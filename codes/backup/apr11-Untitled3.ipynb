{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11466,
     "status": "ok",
     "timestamp": 1618207238268,
     "user": {
      "displayName": "Subhalingam D",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64",
      "userId": "08059846138458314824"
     },
     "user_tz": -330
    },
    "id": "e63q7jUXkG6Y",
    "outputId": "8afff82f-6a0d-4a93-af33-b8efe7cafe1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/a8/a2e2d0750ee17c7e3d81e4695a0338ad0b3f231853b8c3fa339ff2d25c7c/praw-7.2.0-py3-none-any.whl (159kB)\n",
      "\r",
      "\u001b[K     |██                              | 10kB 18.2MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 20kB 18.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 30kB 15.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 40kB 14.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 51kB 11.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 61kB 10.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 71kB 11.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 81kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 92kB 11.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 102kB 10.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 112kB 10.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 122kB 10.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 133kB 10.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 143kB 10.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 153kB 10.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 163kB 10.6MB/s \n",
      "\u001b[?25hCollecting pytesseract\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/e6/a4e9fc8a93c1318540e8de6d8d4beb5749b7960388a7c7f27799fc2dd016/pytesseract-0.3.7.tar.gz\n",
      "Collecting transformers==2.11.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
      "\u001b[K     |████████████████████████████████| 675kB 9.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow==2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.4.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.1.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.19.5)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (3.2.5)\n",
      "Collecting websocket-client>=0.54.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n",
      "\u001b[?25hCollecting prawcore<3,>=2\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/df/4a9106bea0d26689c4b309da20c926a01440ddaf60c09a5ae22684ebd35f/prawcore-2.0.0-py3-none-any.whl\n",
      "Collecting update-checker>=0.18\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/ba/8dd7fa5f0b1c6a8ac62f8f57f7e794160c1f86f31c6d0fb00f582372a3e4/update_checker-0.18.0-py3-none-any.whl\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract->-r requirements.txt (line 2)) (7.1.2)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 23.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (3.0.12)\n",
      "Collecting tokenizers==0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/59/bb06dd5ca53547d523422d32735585493e0103c992a52a97ba3aa3be33bf/tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6MB 37.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (20.9)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 42.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (2019.12.20)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (0.36.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (3.3.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (1.32.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (3.12.4)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (0.3.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (1.12.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (3.7.4.3)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (2.10.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (2.4.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements.txt (line 4)) (1.12)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 5)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 5)) (2018.9)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0->-r requirements.txt (line 3)) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0->-r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0->-r requirements.txt (line 3)) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0->-r requirements.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0->-r requirements.txt (line 3)) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==2.11.0->-r requirements.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow==2.4.1->-r requirements.txt (line 4)) (54.2.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 4)) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 4)) (0.4.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 4)) (1.28.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 4)) (3.8.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 4)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 4)) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 4)) (4.2.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->-r requirements.txt (line 4)) (0.4.8)\n",
      "Building wheels for collected packages: pytesseract, sacremoses\n",
      "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pytesseract: filename=pytesseract-0.3.7-py2.py3-none-any.whl size=13945 sha256=5b94f5ad1e431dd0708c972adf90f3894f4f3b8fff4aa71f4bab25d93b4dce2e\n",
      "  Stored in directory: /root/.cache/pip/wheels/81/20/7e/1dd0daad1575d5260916bb1e9781246430647adaef4b3ca3b3\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=ad8384fc07dd8fbebb42b1d8cd85584b9cbea59e531817dc8994b65972719e51\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
      "Successfully built pytesseract sacremoses\n",
      "Installing collected packages: websocket-client, prawcore, update-checker, praw, pytesseract, sacremoses, tokenizers, sentencepiece, transformers\n",
      "Successfully installed praw-7.2.0 prawcore-2.0.0 pytesseract-0.3.7 sacremoses-0.0.44 sentencepiece-0.1.95 tokenizers-0.7.0 transformers-2.11.0 update-checker-0.18.0 websocket-client-0.58.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 48971,
     "status": "ok",
     "timestamp": 1618207285272,
     "user": {
      "displayName": "Subhalingam D",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64",
      "userId": "08059846138458314824"
     },
     "user_tz": -330
    },
    "id": "SQ1LZhH7lMqU"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/MTL782-Memes Classifier/data_train.pkl\" \"./\"\n",
    "!cp \"/content/drive/MyDrive/MTL782-Memes Classifier/data_test.pkl\" \"./\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 997928,
     "status": "ok",
     "timestamp": 1618141643115,
     "user": {
      "displayName": "Subhalingam D",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64",
      "userId": "08059846138458314824"
     },
     "user_tz": -330
    },
    "id": "xbxD2M_PnLsk",
    "outputId": "bdcfe54c-e7f7-4d29-8d17-444561968251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-11 11:30:46.885139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2021-04-11 11:30:51.956769: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-11 11:30:51.965023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-11 11:30:51.976296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 11:30:51.976827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-04-11 11:30:51.976896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 11:30:51.992125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 11:30:51.992219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-11 11:30:51.999826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-11 11:30:52.004711: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-11 11:30:52.014385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-11 11:30:52.017343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-11 11:30:52.017948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-11 11:30:52.018090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 11:30:52.018931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 11:30:52.019614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-11 11:30:52.020098: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-11 11:30:52.020210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 11:30:52.020708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-04-11 11:30:52.020751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 11:30:52.020786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 11:30:52.020812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-11 11:30:52.020835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-11 11:30:52.020878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-11 11:30:52.020900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-11 11:30:52.020921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-11 11:30:52.020942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-11 11:30:52.021020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 11:30:52.021613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 11:30:52.022136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-11 11:30:52.022197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 11:30:52.525931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-11 11:30:52.525981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-04-11 11:30:52.525995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-04-11 11:30:52.526196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 11:30:52.526781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 11:30:52.527368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 11:30:52.527836: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-04-11 11:30:52.527903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12675 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "2021-04-11 11:30:52.654225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 11:30:53.151090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_imp (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "densenet121 (Functional)        (None, None, None, 1 7037504     img_imp[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bert_input_id (InputLayer)      [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_mask_id (InputLayer)       [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_seg_id (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 50176)        0           densenet121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   bert_input_id[0][0]              \n",
      "                                                                 bert_mask_id[0][0]               \n",
      "                                                                 bert_seg_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         51381248    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          459264      tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          131200      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          16512       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           dropout_38[0][0]                 \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           16448       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            195         dropout_39[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 168,524,611\n",
      "Trainable params: 52,004,867\n",
      "Non-trainable params: 116,519,744\n",
      "__________________________________________________________________________________________________\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "tcmalloc: large alloc 1198809088 bytes == 0x56490ff46000 @  0x7f659d41e1e7 0x7f6598fd646e 0x7f6599026c7b 0x7f6599029e83 0x7f659902a07b 0x7f65990cb761 0x56488b1990e4 0x56488b198de0 0x56488b20d6f5 0x56488b207b0e 0x56488b19a77a 0x56488b20ce50 0x56488b207b0e 0x56488b19a77a 0x56488b208c9e 0x56488b207b0e 0x56488b207813 0x56488b2d1592 0x56488b2d190d 0x56488b2d17b6 0x56488b2a9103 0x56488b2a8dac 0x7f659c208bf7 0x56488b2a8c8a\n",
      "2021-04-11 11:31:31.716056: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-04-11 11:31:31.716520: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
      "Epoch 1/48\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "2021-04-11 11:31:48.883714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "112/112 [==============================] - ETA: 0s - loss: 20.1000 - accuracy: 0.3350 - precision: 0.3517 - recall: 0.2094 - f1: nanWARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "112/112 [==============================] - 65s 217ms/step - loss: 20.0889 - accuracy: 0.3351 - precision: 0.3517 - recall: 0.2089 - f1: nan - val_loss: 16.5759 - val_accuracy: 0.3600 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 2/48\n",
      "112/112 [==============================] - 18s 157ms/step - loss: 15.7324 - accuracy: 0.4108 - precision: 0.4967 - recall: 0.0793 - f1: nan - val_loss: 13.6604 - val_accuracy: 0.3200 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 3/48\n",
      "112/112 [==============================] - 18s 158ms/step - loss: 13.1119 - accuracy: 0.4162 - precision: 0.4924 - recall: 0.1055 - f1: nan - val_loss: 11.7804 - val_accuracy: 0.3800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 4/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 11.4170 - accuracy: 0.4300 - precision: 0.5210 - recall: 0.1282 - f1: nan - val_loss: 10.5379 - val_accuracy: 0.4650 - val_precision: 0.3846 - val_recall: 0.0240 - val_f1: nan\n",
      "Epoch 5/48\n",
      "112/112 [==============================] - 17s 154ms/step - loss: 10.2798 - accuracy: 0.4705 - precision: 0.5838 - recall: 0.1831 - f1: nan - val_loss: 9.7215 - val_accuracy: 0.3900 - val_precision: 0.3077 - val_recall: 0.0385 - val_f1: nan\n",
      "Epoch 6/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 9.4835 - accuracy: 0.4779 - precision: 0.6186 - recall: 0.2442 - f1: nan - val_loss: 9.0945 - val_accuracy: 0.4300 - val_precision: 0.3077 - val_recall: 0.0385 - val_f1: nan\n",
      "Epoch 7/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 8.8758 - accuracy: 0.5154 - precision: 0.6459 - recall: 0.2827 - f1: 0.3866 - val_loss: 8.6671 - val_accuracy: 0.3100 - val_precision: 0.3141 - val_recall: 0.0577 - val_f1: nan\n",
      "Epoch 8/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 8.3351 - accuracy: 0.5478 - precision: 0.6844 - recall: 0.3252 - f1: 0.4337 - val_loss: 8.2645 - val_accuracy: 0.3550 - val_precision: 0.2427 - val_recall: 0.0721 - val_f1: nan\n",
      "Epoch 9/48\n",
      "112/112 [==============================] - 17s 156ms/step - loss: 7.9074 - accuracy: 0.5740 - precision: 0.6771 - recall: 0.3928 - f1: 0.4892 - val_loss: 7.8578 - val_accuracy: 0.3550 - val_precision: 0.3889 - val_recall: 0.1298 - val_f1: nan\n",
      "Epoch 10/48\n",
      "112/112 [==============================] - 17s 156ms/step - loss: 7.4933 - accuracy: 0.6222 - precision: 0.7306 - recall: 0.4238 - f1: 0.5289 - val_loss: 7.4848 - val_accuracy: 0.4850 - val_precision: 0.4855 - val_recall: 0.2019 - val_f1: 0.2798\n",
      "Epoch 11/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 7.0970 - accuracy: 0.6321 - precision: 0.7363 - recall: 0.4682 - f1: 0.5673 - val_loss: 7.2428 - val_accuracy: 0.3350 - val_precision: 0.3695 - val_recall: 0.1683 - val_f1: nan\n",
      "Epoch 12/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 6.7026 - accuracy: 0.6809 - precision: 0.7781 - recall: 0.5468 - f1: 0.6374 - val_loss: 7.0173 - val_accuracy: 0.3400 - val_precision: 0.3965 - val_recall: 0.2356 - val_f1: 0.2920\n",
      "Epoch 13/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 6.3893 - accuracy: 0.7044 - precision: 0.7933 - recall: 0.6045 - f1: 0.6837 - val_loss: 6.7724 - val_accuracy: 0.3900 - val_precision: 0.3595 - val_recall: 0.2212 - val_f1: 0.2713\n",
      "Epoch 14/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 6.0489 - accuracy: 0.7536 - precision: 0.8233 - recall: 0.6604 - f1: 0.7303 - val_loss: 6.6006 - val_accuracy: 0.3400 - val_precision: 0.3259 - val_recall: 0.2260 - val_f1: nan\n",
      "Epoch 15/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 5.7374 - accuracy: 0.7579 - precision: 0.8384 - recall: 0.6971 - f1: 0.7590 - val_loss: 6.2771 - val_accuracy: 0.3900 - val_precision: 0.3885 - val_recall: 0.2740 - val_f1: 0.3177\n",
      "Epoch 16/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 5.4902 - accuracy: 0.7824 - precision: 0.8326 - recall: 0.7206 - f1: 0.7703 - val_loss: 6.0965 - val_accuracy: 0.3650 - val_precision: 0.4268 - val_recall: 0.3221 - val_f1: 0.3656\n",
      "Epoch 17/48\n",
      "112/112 [==============================] - 17s 156ms/step - loss: 5.2231 - accuracy: 0.8152 - precision: 0.8594 - recall: 0.7594 - f1: 0.8047 - val_loss: 5.9600 - val_accuracy: 0.3600 - val_precision: 0.3847 - val_recall: 0.3077 - val_f1: 0.3407\n",
      "Epoch 18/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 4.9590 - accuracy: 0.8459 - precision: 0.8838 - recall: 0.8142 - f1: 0.8463 - val_loss: 5.7871 - val_accuracy: 0.3900 - val_precision: 0.4154 - val_recall: 0.3413 - val_f1: 0.3742\n",
      "Epoch 19/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 4.7498 - accuracy: 0.8529 - precision: 0.8792 - recall: 0.8118 - f1: 0.8432 - val_loss: 5.9842 - val_accuracy: 0.3400 - val_precision: 0.3469 - val_recall: 0.3221 - val_f1: 0.3337\n",
      "Epoch 20/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 4.5333 - accuracy: 0.8599 - precision: 0.8870 - recall: 0.8228 - f1: 0.8527 - val_loss: 5.6456 - val_accuracy: 0.3750 - val_precision: 0.3760 - val_recall: 0.3317 - val_f1: 0.3517\n",
      "Epoch 21/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 4.3163 - accuracy: 0.8888 - precision: 0.9023 - recall: 0.8604 - f1: 0.8802 - val_loss: 5.4961 - val_accuracy: 0.3550 - val_precision: 0.3395 - val_recall: 0.2981 - val_f1: 0.3173\n",
      "Epoch 22/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 4.1362 - accuracy: 0.8855 - precision: 0.9153 - recall: 0.8535 - f1: 0.8821 - val_loss: 5.5239 - val_accuracy: 0.3550 - val_precision: 0.3570 - val_recall: 0.3317 - val_f1: 0.3436\n",
      "Epoch 23/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 3.9541 - accuracy: 0.8970 - precision: 0.9176 - recall: 0.8782 - f1: 0.8968 - val_loss: 5.3735 - val_accuracy: 0.3400 - val_precision: 0.3217 - val_recall: 0.2933 - val_f1: 0.3065\n",
      "Epoch 24/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 3.7836 - accuracy: 0.9121 - precision: 0.9273 - recall: 0.8898 - f1: 0.9075 - val_loss: 5.1428 - val_accuracy: 0.3750 - val_precision: 0.3631 - val_recall: 0.3125 - val_f1: 0.3353\n",
      "Epoch 25/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 3.6275 - accuracy: 0.9168 - precision: 0.9317 - recall: 0.8999 - f1: 0.9150 - val_loss: 4.9802 - val_accuracy: 0.3400 - val_precision: 0.3436 - val_recall: 0.3125 - val_f1: 0.3267\n",
      "Epoch 26/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 3.4803 - accuracy: 0.9204 - precision: 0.9340 - recall: 0.8994 - f1: 0.9159 - val_loss: 4.8970 - val_accuracy: 0.3650 - val_precision: 0.3778 - val_recall: 0.3413 - val_f1: 0.3581\n",
      "Epoch 27/48\n",
      "112/112 [==============================] - 17s 156ms/step - loss: 3.3440 - accuracy: 0.9235 - precision: 0.9366 - recall: 0.9079 - f1: 0.9215 - val_loss: 4.7862 - val_accuracy: 0.4050 - val_precision: 0.4198 - val_recall: 0.3990 - val_f1: 0.4088\n",
      "Epoch 28/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 3.2177 - accuracy: 0.9219 - precision: 0.9370 - recall: 0.9080 - f1: 0.9219 - val_loss: 4.8467 - val_accuracy: 0.3650 - val_precision: 0.3590 - val_recall: 0.3413 - val_f1: 0.3494\n",
      "Epoch 29/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 3.0557 - accuracy: 0.9394 - precision: 0.9548 - recall: 0.9310 - f1: 0.9423 - val_loss: 4.5715 - val_accuracy: 0.3700 - val_precision: 0.3839 - val_recall: 0.3462 - val_f1: 0.3636\n",
      "Epoch 30/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 2.9452 - accuracy: 0.9467 - precision: 0.9543 - recall: 0.9303 - f1: 0.9418 - val_loss: 4.5071 - val_accuracy: 0.3650 - val_precision: 0.3703 - val_recall: 0.3462 - val_f1: 0.3574\n",
      "Epoch 31/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 2.8260 - accuracy: 0.9475 - precision: 0.9605 - recall: 0.9415 - f1: 0.9506 - val_loss: 4.6363 - val_accuracy: 0.3150 - val_precision: 0.3168 - val_recall: 0.2933 - val_f1: 0.3043\n",
      "Epoch 32/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 2.7307 - accuracy: 0.9473 - precision: 0.9601 - recall: 0.9435 - f1: 0.9515 - val_loss: 4.5013 - val_accuracy: 0.3950 - val_precision: 0.3790 - val_recall: 0.3558 - val_f1: 0.3667\n",
      "Epoch 33/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 2.6386 - accuracy: 0.9528 - precision: 0.9601 - recall: 0.9456 - f1: 0.9526 - val_loss: 4.8844 - val_accuracy: 0.3500 - val_precision: 0.3420 - val_recall: 0.3317 - val_f1: 0.3367\n",
      "Epoch 34/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 2.5186 - accuracy: 0.9550 - precision: 0.9628 - recall: 0.9455 - f1: 0.9536 - val_loss: 4.4082 - val_accuracy: 0.3750 - val_precision: 0.3849 - val_recall: 0.3606 - val_f1: 0.3721\n",
      "Epoch 35/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 2.4240 - accuracy: 0.9572 - precision: 0.9613 - recall: 0.9504 - f1: 0.9556 - val_loss: 4.4066 - val_accuracy: 0.3700 - val_precision: 0.3726 - val_recall: 0.3462 - val_f1: 0.3587\n",
      "Epoch 36/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 2.3390 - accuracy: 0.9532 - precision: 0.9567 - recall: 0.9466 - f1: 0.9515 - val_loss: 4.3627 - val_accuracy: 0.3650 - val_precision: 0.3625 - val_recall: 0.3558 - val_f1: 0.3590\n",
      "Epoch 37/48\n",
      "112/112 [==============================] - 17s 154ms/step - loss: 2.2281 - accuracy: 0.9763 - precision: 0.9790 - recall: 0.9700 - f1: 0.9744 - val_loss: 4.2605 - val_accuracy: 0.3450 - val_precision: 0.3399 - val_recall: 0.3125 - val_f1: 0.3253\n",
      "Epoch 38/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 2.1581 - accuracy: 0.9698 - precision: 0.9721 - recall: 0.9650 - f1: 0.9684 - val_loss: 4.0561 - val_accuracy: 0.3450 - val_precision: 0.3633 - val_recall: 0.3365 - val_f1: 0.3489\n",
      "Epoch 39/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 2.0689 - accuracy: 0.9740 - precision: 0.9795 - recall: 0.9635 - f1: 0.9712 - val_loss: 4.3172 - val_accuracy: 0.3100 - val_precision: 0.2953 - val_recall: 0.2885 - val_f1: nan\n",
      "Epoch 40/48\n",
      "112/112 [==============================] - 17s 156ms/step - loss: 2.0201 - accuracy: 0.9584 - precision: 0.9672 - recall: 0.9521 - f1: 0.9593 - val_loss: 4.3831 - val_accuracy: 0.3250 - val_precision: 0.3199 - val_recall: 0.2981 - val_f1: 0.3083\n",
      "Epoch 41/48\n",
      "112/112 [==============================] - 17s 156ms/step - loss: 1.9408 - accuracy: 0.9646 - precision: 0.9696 - recall: 0.9641 - f1: 0.9668 - val_loss: 4.1718 - val_accuracy: 0.3400 - val_precision: 0.3397 - val_recall: 0.3269 - val_f1: 0.3330\n",
      "Epoch 42/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 1.8630 - accuracy: 0.9699 - precision: 0.9731 - recall: 0.9669 - f1: 0.9699 - val_loss: 3.8684 - val_accuracy: 0.4000 - val_precision: 0.4043 - val_recall: 0.3798 - val_f1: 0.3911\n",
      "Epoch 43/48\n",
      "112/112 [==============================] - 17s 156ms/step - loss: 1.7895 - accuracy: 0.9741 - precision: 0.9781 - recall: 0.9708 - f1: 0.9743 - val_loss: 4.4901 - val_accuracy: 0.3050 - val_precision: 0.3060 - val_recall: 0.2981 - val_f1: 0.3019\n",
      "Epoch 44/48\n",
      "112/112 [==============================] - 17s 156ms/step - loss: 1.7495 - accuracy: 0.9623 - precision: 0.9687 - recall: 0.9584 - f1: 0.9634 - val_loss: 4.3232 - val_accuracy: 0.3050 - val_precision: 0.3040 - val_recall: 0.2885 - val_f1: nan\n",
      "Epoch 45/48\n",
      "112/112 [==============================] - 17s 156ms/step - loss: 1.6936 - accuracy: 0.9618 - precision: 0.9668 - recall: 0.9555 - f1: 0.9610 - val_loss: 4.6064 - val_accuracy: 0.3450 - val_precision: 0.3304 - val_recall: 0.3221 - val_f1: 0.3261\n",
      "Epoch 46/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 1.6959 - accuracy: 0.9401 - precision: 0.9464 - recall: 0.9325 - f1: 0.9391 - val_loss: 4.0671 - val_accuracy: 0.3450 - val_precision: 0.3401 - val_recall: 0.3269 - val_f1: 0.3332\n",
      "Epoch 47/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 1.5614 - accuracy: 0.9767 - precision: 0.9796 - recall: 0.9697 - f1: 0.9745 - val_loss: 3.8138 - val_accuracy: 0.3850 - val_precision: 0.3815 - val_recall: 0.3558 - val_f1: 0.3678\n",
      "Epoch 48/48\n",
      "112/112 [==============================] - 17s 155ms/step - loss: 1.4870 - accuracy: 0.9836 - precision: 0.9847 - recall: 0.9814 - f1: 0.9830 - val_loss: 4.0622 - val_accuracy: 0.3950 - val_precision: 0.3871 - val_recall: 0.3702 - val_f1: 0.3782\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_imp (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "densenet121 (Functional)        (None, None, None, 1 7037504     img_imp[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bert_input_id (InputLayer)      [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_mask_id (InputLayer)       [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_seg_id (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50176)        0           densenet121[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   bert_input_id[0][0]              \n",
      "                                                                 bert_mask_id[0][0]               \n",
      "                                                                 bert_seg_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         51381248    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          459264      tf_bert_model[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          131200      dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16512       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           dropout_41[0][0]                 \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           16448       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 64)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 3)            195         dropout_42[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 168,524,611\n",
      "Trainable params: 52,004,867\n",
      "Non-trainable params: 116,519,744\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROU0e-ipDKeH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEEtro0bDK1l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 638348,
     "status": "ok",
     "timestamp": 1618148716275,
     "user": {
      "displayName": "Subhalingam D",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64",
      "userId": "08059846138458314824"
     },
     "user_tz": -330
    },
    "id": "PTGt44QmDLEN",
    "outputId": "32f40488-687d-4ad1-ce1c-2e7dfa86c43e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-11 13:34:39.880479: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2021-04-11 13:34:44.073044: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-11 13:34:44.073919: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-11 13:34:44.086228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:34:44.086749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-04-11 13:34:44.086797: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 13:34:44.090815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 13:34:44.090921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-11 13:34:44.095484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-11 13:34:44.095881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-11 13:34:44.097947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-11 13:34:44.099297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-11 13:34:44.099564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-11 13:34:44.099688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:34:44.100277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:34:44.100769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-11 13:34:44.101184: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-11 13:34:44.101298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:34:44.101781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-04-11 13:34:44.101824: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 13:34:44.101869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 13:34:44.101906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-11 13:34:44.101930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-11 13:34:44.101951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-11 13:34:44.101972: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-11 13:34:44.101992: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-11 13:34:44.102014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-11 13:34:44.102082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:34:44.102596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:34:44.103127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-11 13:34:44.103193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 13:34:44.622539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-11 13:34:44.622593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-04-11 13:34:44.622609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-04-11 13:34:44.622814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:34:44.623455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:34:44.624013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:34:44.624486: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-04-11 13:34:44.624548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12675 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "2021-04-11 13:34:44.749924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 13:34:45.262982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_imp (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "densenet121 (Functional)        (None, None, None, 1 7037504     img_imp[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 50176)        0           densenet121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bert_input_id (InputLayer)      [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_mask_id (InputLayer)       [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_seg_id (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 50176)        200704      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   bert_input_id[0][0]              \n",
      "                                                                 bert_mask_id[0][0]               \n",
      "                                                                 bert_seg_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         51381248    batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 768)          3072        global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          262400      dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           dropout_39[0][0]                 \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           32832       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            195         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 168,597,059\n",
      "Trainable params: 51,975,427\n",
      "Non-trainable params: 116,621,632\n",
      "__________________________________________________________________________________________________\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "tcmalloc: large alloc 1198809088 bytes == 0x56217a3aa000 @  0x7feb2547a1e7 0x7feb20ff246e 0x7feb21042c7b 0x7feb21045e83 0x7feb2104607b 0x7feb210e7761 0x5620f53ac0e4 0x5620f53abde0 0x5620f54206f5 0x5620f541ab0e 0x5620f53ad77a 0x5620f541fe50 0x5620f541ab0e 0x5620f53ad77a 0x5620f541bc9e 0x5620f541ab0e 0x5620f541a813 0x5620f54e4592 0x5620f54e490d 0x5620f54e47b6 0x5620f54bc103 0x5620f54bbdac 0x7feb24264bf7 0x5620f54bbc8a\n",
      "2021-04-11 13:35:13.671977: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-04-11 13:35:13.672595: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
      "Epoch 1/48\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "2021-04-11 13:35:30.232841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "112/112 [==============================] - ETA: 0s - loss: 97.3497 - accuracy: 0.3221 - precision: 0.3122 - recall: 0.2323 - f1: nanWARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "112/112 [==============================] - 70s 212ms/step - loss: 97.3038 - accuracy: 0.3222 - precision: 0.3123 - recall: 0.2324 - f1: nan - val_loss: 82.1788 - val_accuracy: 0.4000 - val_precision: 0.3810 - val_recall: 0.1298 - val_f1: nan\n",
      "Epoch 2/48\n",
      "112/112 [==============================] - 17s 153ms/step - loss: 78.1697 - accuracy: 0.5316 - precision: 0.5884 - recall: 0.4171 - f1: 0.4849 - val_loss: 67.8368 - val_accuracy: 0.4000 - val_precision: 0.4157 - val_recall: 0.1827 - val_f1: nan\n",
      "Epoch 3/48\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 64.7085 - accuracy: 0.6356 - precision: 0.7053 - recall: 0.5056 - f1: 0.5846 - val_loss: 57.4419 - val_accuracy: 0.3800 - val_precision: 0.3861 - val_recall: 0.1875 - val_f1: 0.2496\n",
      "Epoch 4/48\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 54.8228 - accuracy: 0.7572 - precision: 0.8219 - recall: 0.6663 - f1: 0.7339 - val_loss: 49.6011 - val_accuracy: 0.3900 - val_precision: 0.4348 - val_recall: 0.2740 - val_f1: 0.3341\n",
      "Epoch 5/48\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 47.3313 - accuracy: 0.8026 - precision: 0.8502 - recall: 0.7143 - f1: 0.7737 - val_loss: 43.4761 - val_accuracy: 0.3950 - val_precision: 0.4074 - val_recall: 0.2837 - val_f1: 0.3327\n",
      "Epoch 6/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 41.3184 - accuracy: 0.8744 - precision: 0.9009 - recall: 0.8269 - f1: 0.8611 - val_loss: 38.4390 - val_accuracy: 0.3700 - val_precision: 0.4048 - val_recall: 0.2837 - val_f1: 0.3302\n",
      "Epoch 7/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 36.3398 - accuracy: 0.9116 - precision: 0.9375 - recall: 0.8809 - f1: 0.9075 - val_loss: 34.1641 - val_accuracy: 0.3600 - val_precision: 0.3615 - val_recall: 0.2885 - val_f1: 0.3203\n",
      "Epoch 8/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 32.0633 - accuracy: 0.9329 - precision: 0.9558 - recall: 0.9139 - f1: 0.9338 - val_loss: 30.3154 - val_accuracy: 0.3950 - val_precision: 0.4181 - val_recall: 0.3029 - val_f1: 0.3499\n",
      "Epoch 9/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 28.2650 - accuracy: 0.9616 - precision: 0.9691 - recall: 0.9460 - f1: 0.9571 - val_loss: 27.0043 - val_accuracy: 0.3350 - val_precision: 0.3574 - val_recall: 0.2885 - val_f1: 0.3188\n",
      "Epoch 10/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 24.8978 - accuracy: 0.9586 - precision: 0.9705 - recall: 0.9376 - f1: 0.9532 - val_loss: 23.8823 - val_accuracy: 0.3500 - val_precision: 0.3754 - val_recall: 0.2933 - val_f1: 0.3286\n",
      "Epoch 11/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 21.8651 - accuracy: 0.9696 - precision: 0.9779 - recall: 0.9603 - f1: 0.9687 - val_loss: 21.1604 - val_accuracy: 0.3750 - val_precision: 0.3777 - val_recall: 0.2981 - val_f1: 0.3312\n",
      "Epoch 12/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 19.1266 - accuracy: 0.9726 - precision: 0.9794 - recall: 0.9686 - f1: 0.9737 - val_loss: 18.6652 - val_accuracy: 0.3850 - val_precision: 0.3885 - val_recall: 0.3317 - val_f1: 0.3573\n",
      "Epoch 13/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 16.6836 - accuracy: 0.9746 - precision: 0.9788 - recall: 0.9693 - f1: 0.9738 - val_loss: 16.5358 - val_accuracy: 0.3700 - val_precision: 0.3430 - val_recall: 0.3029 - val_f1: 0.3211\n",
      "Epoch 14/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 14.4991 - accuracy: 0.9765 - precision: 0.9814 - recall: 0.9738 - f1: 0.9775 - val_loss: 14.5875 - val_accuracy: 0.3700 - val_precision: 0.3610 - val_recall: 0.3077 - val_f1: 0.3317\n",
      "Epoch 15/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 12.5620 - accuracy: 0.9782 - precision: 0.9825 - recall: 0.9778 - f1: 0.9800 - val_loss: 12.8019 - val_accuracy: 0.3950 - val_precision: 0.3968 - val_recall: 0.3606 - val_f1: 0.3776\n",
      "Epoch 16/48\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 10.8755 - accuracy: 0.9808 - precision: 0.9859 - recall: 0.9782 - f1: 0.9819 - val_loss: 11.3619 - val_accuracy: 0.3900 - val_precision: 0.3938 - val_recall: 0.3654 - val_f1: 0.3788\n",
      "Epoch 17/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 9.3820 - accuracy: 0.9857 - precision: 0.9878 - recall: 0.9824 - f1: 0.9850 - val_loss: 10.0194 - val_accuracy: 0.3500 - val_precision: 0.3597 - val_recall: 0.3077 - val_f1: 0.3313\n",
      "Epoch 18/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 8.1143 - accuracy: 0.9813 - precision: 0.9813 - recall: 0.9773 - f1: 0.9792 - val_loss: 8.9044 - val_accuracy: 0.3950 - val_precision: 0.3881 - val_recall: 0.3365 - val_f1: 0.3590\n",
      "Epoch 19/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 6.9977 - accuracy: 0.9884 - precision: 0.9895 - recall: 0.9853 - f1: 0.9873 - val_loss: 8.0365 - val_accuracy: 0.3450 - val_precision: 0.3491 - val_recall: 0.3125 - val_f1: 0.3293\n",
      "Epoch 20/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 6.0675 - accuracy: 0.9845 - precision: 0.9872 - recall: 0.9834 - f1: 0.9852 - val_loss: 7.3992 - val_accuracy: 0.3100 - val_precision: 0.2960 - val_recall: 0.2692 - val_f1: 0.2818\n",
      "Epoch 21/48\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 5.2797 - accuracy: 0.9773 - precision: 0.9788 - recall: 0.9725 - f1: 0.9755 - val_loss: 6.5786 - val_accuracy: 0.3750 - val_precision: 0.3711 - val_recall: 0.3462 - val_f1: 0.3579\n",
      "Epoch 22/48\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 4.6466 - accuracy: 0.9804 - precision: 0.9835 - recall: 0.9760 - f1: 0.9796 - val_loss: 6.0941 - val_accuracy: 0.3550 - val_precision: 0.3510 - val_recall: 0.3173 - val_f1: 0.3327\n",
      "Epoch 23/48\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 4.1408 - accuracy: 0.9775 - precision: 0.9802 - recall: 0.9732 - f1: 0.9765 - val_loss: 5.6262 - val_accuracy: 0.3850 - val_precision: 0.3889 - val_recall: 0.3606 - val_f1: 0.3737\n",
      "Epoch 24/48\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 3.7139 - accuracy: 0.9711 - precision: 0.9769 - recall: 0.9673 - f1: 0.9719 - val_loss: 5.3486 - val_accuracy: 0.3700 - val_precision: 0.3572 - val_recall: 0.3269 - val_f1: 0.3411\n",
      "Epoch 25/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 3.3464 - accuracy: 0.9744 - precision: 0.9752 - recall: 0.9720 - f1: 0.9736 - val_loss: 4.9579 - val_accuracy: 0.3850 - val_precision: 0.3905 - val_recall: 0.3606 - val_f1: 0.3745\n",
      "Epoch 26/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 3.0535 - accuracy: 0.9668 - precision: 0.9720 - recall: 0.9658 - f1: 0.9688 - val_loss: 4.9277 - val_accuracy: 0.4050 - val_precision: 0.4028 - val_recall: 0.3750 - val_f1: 0.3881\n",
      "Epoch 27/48\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 2.8266 - accuracy: 0.9614 - precision: 0.9702 - recall: 0.9583 - f1: 0.9641 - val_loss: 4.6792 - val_accuracy: 0.3650 - val_precision: 0.3713 - val_recall: 0.3510 - val_f1: 0.3604\n",
      "Epoch 28/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 2.5748 - accuracy: 0.9797 - precision: 0.9808 - recall: 0.9783 - f1: 0.9795 - val_loss: 4.6786 - val_accuracy: 0.3650 - val_precision: 0.3613 - val_recall: 0.3462 - val_f1: 0.3534\n",
      "Epoch 29/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 2.3841 - accuracy: 0.9764 - precision: 0.9791 - recall: 0.9755 - f1: 0.9773 - val_loss: 4.6282 - val_accuracy: 0.3500 - val_precision: 0.3429 - val_recall: 0.3269 - val_f1: 0.3345\n",
      "Epoch 30/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 2.2478 - accuracy: 0.9788 - precision: 0.9813 - recall: 0.9741 - f1: 0.9775 - val_loss: 4.4807 - val_accuracy: 0.3450 - val_precision: 0.3415 - val_recall: 0.3221 - val_f1: 0.3311\n",
      "Epoch 31/48\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 2.1101 - accuracy: 0.9688 - precision: 0.9701 - recall: 0.9667 - f1: 0.9683 - val_loss: 4.3880 - val_accuracy: 0.3550 - val_precision: 0.3498 - val_recall: 0.3269 - val_f1: 0.3376\n",
      "Epoch 32/48\n",
      "112/112 [==============================] - 17s 150ms/step - loss: 1.9977 - accuracy: 0.9763 - precision: 0.9774 - recall: 0.9741 - f1: 0.9757 - val_loss: 4.2241 - val_accuracy: 0.4000 - val_precision: 0.3922 - val_recall: 0.3702 - val_f1: 0.3806\n",
      "Epoch 33/48\n",
      " 31/112 [=======>......................] - ETA: 11s - loss: 1.8991 - accuracy: 0.9834 - precision: 0.9881 - recall: 0.9823 - f1: 0.9851Traceback (most recent call last):\n",
      "  File \"train.py\", line 10, in <module>\n",
      "    cls.train(data)\n",
      "  File \"/content/model.py\", line 111, in train\n",
      "    epochs=self.epochs,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 855, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 2943, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 560, in call\n",
      "    ctx=ctx)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1IVvpCZsGgK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 956958,
     "status": "ok",
     "timestamp": 1618143751634,
     "user": {
      "displayName": "Subhalingam D",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64",
      "userId": "08059846138458314824"
     },
     "user_tz": -330
    },
    "id": "1DaBXRH-woJo",
    "outputId": "1cae7b8f-944c-4031-ac73-8ca9dc765ea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-11 12:06:35.800879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2021-04-11 12:06:38.125414: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-11 12:06:38.126427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-11 12:06:38.132668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 12:06:38.133235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-04-11 12:06:38.133286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 12:06:38.138671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 12:06:38.138757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-11 12:06:38.140604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-11 12:06:38.141001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-11 12:06:38.143034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-11 12:06:38.143672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-11 12:06:38.143935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-11 12:06:38.144043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 12:06:38.144589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 12:06:38.145089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-11 12:06:38.145489: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-11 12:06:38.145621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 12:06:38.146121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-04-11 12:06:38.146167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 12:06:38.146207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 12:06:38.146236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-11 12:06:38.146259: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-11 12:06:38.146280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-11 12:06:38.146301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-11 12:06:38.146322: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-11 12:06:38.146344: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-11 12:06:38.146414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 12:06:38.146964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 12:06:38.147443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-11 12:06:38.147502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 12:06:38.668989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-11 12:06:38.669037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-04-11 12:06:38.669057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-04-11 12:06:38.669270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 12:06:38.670139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 12:06:38.670933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 12:06:38.671430: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-04-11 12:06:38.671489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12675 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "2021-04-11 12:06:38.802515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 12:06:39.323884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_imp (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "densenet121 (Functional)        (None, None, None, 1 7037504     img_imp[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bert_input_id (InputLayer)      [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_mask_id (InputLayer)       [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_seg_id (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 50176)        0           densenet121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   bert_input_id[0][0]              \n",
      "                                                                 bert_mask_id[0][0]               \n",
      "                                                                 bert_seg_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         51381248    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          131200      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          98432       global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           dropout_38[0][0]                 \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           16448       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            195         dropout_39[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 168,147,267\n",
      "Trainable params: 51,627,523\n",
      "Non-trainable params: 116,519,744\n",
      "__________________________________________________________________________________________________\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "tcmalloc: large alloc 1198809088 bytes == 0x563f85fc8000 @  0x7f8cee55f1e7 0x7f8cea11746e 0x7f8cea167c7b 0x7f8cea16ae83 0x7f8cea16b07b 0x7f8cea20c761 0x563effd060e4 0x563effd05de0 0x563effd7a6f5 0x563effd74b0e 0x563effd0777a 0x563effd79e50 0x563effd74b0e 0x563effd0777a 0x563effd75c9e 0x563effd74b0e 0x563effd74813 0x563effe3e592 0x563effe3e90d 0x563effe3e7b6 0x563effe16103 0x563effe15dac 0x7f8ced349bf7 0x563effe15c8a\n",
      "2021-04-11 12:06:52.285805: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-04-11 12:06:52.286299: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
      "Epoch 1/48\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "2021-04-11 12:07:08.646004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "112/112 [==============================] - ETA: 0s - loss: 93.8370 - accuracy: 0.3279 - precision: 0.3232 - recall: 0.2115 - f1: nanWARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "112/112 [==============================] - 70s 211ms/step - loss: 93.7719 - accuracy: 0.3278 - precision: 0.3231 - recall: 0.2111 - f1: nan - val_loss: 72.7382 - val_accuracy: 0.4250 - val_precision: 0.0769 - val_recall: 0.0048 - val_f1: nan\n",
      "Epoch 2/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 67.5348 - accuracy: 0.3472 - precision: 0.3564 - recall: 0.1324 - f1: nan - val_loss: 53.7614 - val_accuracy: 0.3200 - val_precision: 0.2564 - val_recall: 0.0240 - val_f1: nan\n",
      "Epoch 3/48\n",
      "112/112 [==============================] - 17s 154ms/step - loss: 50.2506 - accuracy: 0.4030 - precision: 0.4484 - recall: 0.1710 - f1: nan - val_loss: 41.1237 - val_accuracy: 0.3650 - val_precision: 0.2051 - val_recall: 0.0192 - val_f1: nan\n",
      "Epoch 4/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 38.7812 - accuracy: 0.4139 - precision: 0.4619 - recall: 0.1543 - f1: nan - val_loss: 32.6064 - val_accuracy: 0.4050 - val_precision: 0.3654 - val_recall: 0.0481 - val_f1: nan\n",
      "Epoch 5/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 30.9591 - accuracy: 0.4415 - precision: 0.5172 - recall: 0.2112 - f1: nan - val_loss: 26.6869 - val_accuracy: 0.4050 - val_precision: 0.4744 - val_recall: 0.0673 - val_f1: nan\n",
      "Epoch 6/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 25.4535 - accuracy: 0.4664 - precision: 0.5549 - recall: 0.2342 - f1: nan - val_loss: 22.3272 - val_accuracy: 0.4800 - val_precision: 0.5128 - val_recall: 0.0577 - val_f1: nan\n",
      "Epoch 7/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 21.4465 - accuracy: 0.4579 - precision: 0.5115 - recall: 0.2273 - f1: nan - val_loss: 19.0468 - val_accuracy: 0.4400 - val_precision: 0.6082 - val_recall: 0.1250 - val_f1: nan\n",
      "Epoch 8/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 18.3009 - accuracy: 0.5066 - precision: 0.5784 - recall: 0.2789 - f1: nan - val_loss: 16.4792 - val_accuracy: 0.4250 - val_precision: 0.3154 - val_recall: 0.0673 - val_f1: nan\n",
      "Epoch 9/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 15.8069 - accuracy: 0.5139 - precision: 0.6106 - recall: 0.3131 - f1: 0.4075 - val_loss: 14.4034 - val_accuracy: 0.4250 - val_precision: 0.3978 - val_recall: 0.1538 - val_f1: nan\n",
      "Epoch 10/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 13.7529 - accuracy: 0.5410 - precision: 0.6507 - recall: 0.3914 - f1: 0.4834 - val_loss: 12.6706 - val_accuracy: 0.3800 - val_precision: 0.3979 - val_recall: 0.2500 - val_f1: 0.3051\n",
      "Epoch 11/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 12.0313 - accuracy: 0.5729 - precision: 0.6714 - recall: 0.4430 - f1: 0.5301 - val_loss: 11.2320 - val_accuracy: 0.4150 - val_precision: 0.3194 - val_recall: 0.1442 - val_f1: nan\n",
      "Epoch 12/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 10.5971 - accuracy: 0.6271 - precision: 0.7052 - recall: 0.4791 - f1: 0.5670 - val_loss: 10.0238 - val_accuracy: 0.4000 - val_precision: 0.3380 - val_recall: 0.1106 - val_f1: nan\n",
      "Epoch 13/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 9.3718 - accuracy: 0.6633 - precision: 0.7608 - recall: 0.5034 - f1: 0.6010 - val_loss: 9.0149 - val_accuracy: 0.4200 - val_precision: 0.4614 - val_recall: 0.2548 - val_f1: 0.3262\n",
      "Epoch 14/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 8.3168 - accuracy: 0.6848 - precision: 0.7606 - recall: 0.5870 - f1: 0.6591 - val_loss: 8.2199 - val_accuracy: 0.3350 - val_precision: 0.3430 - val_recall: 0.2067 - val_f1: 0.2565\n",
      "Epoch 15/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 7.4317 - accuracy: 0.7145 - precision: 0.7765 - recall: 0.5997 - f1: 0.6742 - val_loss: 7.5404 - val_accuracy: 0.4350 - val_precision: 0.4185 - val_recall: 0.3077 - val_f1: 0.3537\n",
      "Epoch 16/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 6.7299 - accuracy: 0.6880 - precision: 0.7662 - recall: 0.6037 - f1: 0.6728 - val_loss: 7.1240 - val_accuracy: 0.3500 - val_precision: 0.3636 - val_recall: 0.2981 - val_f1: 0.3262\n",
      "Epoch 17/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 6.1028 - accuracy: 0.7154 - precision: 0.7836 - recall: 0.6339 - f1: 0.6975 - val_loss: 6.4197 - val_accuracy: 0.4000 - val_precision: 0.3749 - val_recall: 0.3077 - val_f1: 0.3372\n",
      "Epoch 18/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 5.4885 - accuracy: 0.7722 - precision: 0.8210 - recall: 0.7008 - f1: 0.7541 - val_loss: 5.8616 - val_accuracy: 0.3950 - val_precision: 0.4288 - val_recall: 0.2788 - val_f1: 0.3362\n",
      "Epoch 19/48\n",
      "112/112 [==============================] - 17s 153ms/step - loss: 4.9905 - accuracy: 0.7986 - precision: 0.8538 - recall: 0.7356 - f1: 0.7883 - val_loss: 5.4278 - val_accuracy: 0.4100 - val_precision: 0.4434 - val_recall: 0.2885 - val_f1: nan\n",
      "Epoch 20/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 4.5667 - accuracy: 0.8059 - precision: 0.8578 - recall: 0.7497 - f1: 0.7984 - val_loss: 5.2663 - val_accuracy: 0.3750 - val_precision: 0.3781 - val_recall: 0.2933 - val_f1: 0.3290\n",
      "Epoch 21/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 4.1490 - accuracy: 0.8408 - precision: 0.8704 - recall: 0.7944 - f1: 0.8293 - val_loss: 4.9154 - val_accuracy: 0.3500 - val_precision: 0.3492 - val_recall: 0.2596 - val_f1: 0.2968\n",
      "Epoch 22/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 3.7806 - accuracy: 0.8727 - precision: 0.8996 - recall: 0.8317 - f1: 0.8637 - val_loss: 4.6190 - val_accuracy: 0.3950 - val_precision: 0.4115 - val_recall: 0.3462 - val_f1: 0.3749\n",
      "Epoch 23/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 3.4979 - accuracy: 0.8643 - precision: 0.8900 - recall: 0.8271 - f1: 0.8563 - val_loss: 4.5775 - val_accuracy: 0.3400 - val_precision: 0.3246 - val_recall: 0.2740 - val_f1: nan\n",
      "Epoch 24/48\n",
      "112/112 [==============================] - 17s 151ms/step - loss: 3.2254 - accuracy: 0.8762 - precision: 0.9035 - recall: 0.8405 - f1: 0.8700 - val_loss: 4.2050 - val_accuracy: 0.3850 - val_precision: 0.4179 - val_recall: 0.3654 - val_f1: 0.3891\n",
      "Epoch 25/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 2.9926 - accuracy: 0.8778 - precision: 0.8968 - recall: 0.8518 - f1: 0.8732 - val_loss: 4.2223 - val_accuracy: 0.3350 - val_precision: 0.3503 - val_recall: 0.3029 - val_f1: 0.3242\n",
      "Epoch 26/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 2.7543 - accuracy: 0.8944 - precision: 0.9197 - recall: 0.8662 - f1: 0.8911 - val_loss: 3.9743 - val_accuracy: 0.3350 - val_precision: 0.3599 - val_recall: 0.3029 - val_f1: 0.3276\n",
      "Epoch 27/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 2.5363 - accuracy: 0.9167 - precision: 0.9397 - recall: 0.8962 - f1: 0.9169 - val_loss: 4.0219 - val_accuracy: 0.3250 - val_precision: 0.3078 - val_recall: 0.2837 - val_f1: 0.2945\n",
      "Epoch 28/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 2.3740 - accuracy: 0.9028 - precision: 0.9212 - recall: 0.8803 - f1: 0.8995 - val_loss: 3.7237 - val_accuracy: 0.3500 - val_precision: 0.3478 - val_recall: 0.2981 - val_f1: 0.3203\n",
      "Epoch 29/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 2.2431 - accuracy: 0.8944 - precision: 0.9226 - recall: 0.8816 - f1: 0.9009 - val_loss: 4.0913 - val_accuracy: 0.3400 - val_precision: 0.3412 - val_recall: 0.3269 - val_f1: 0.3335\n",
      "Epoch 30/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 2.0897 - accuracy: 0.9092 - precision: 0.9228 - recall: 0.8914 - f1: 0.9062 - val_loss: 3.5086 - val_accuracy: 0.3700 - val_precision: 0.3507 - val_recall: 0.3125 - val_f1: 0.3295\n",
      "Epoch 31/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 1.9857 - accuracy: 0.9186 - precision: 0.9332 - recall: 0.8886 - f1: 0.9096 - val_loss: 3.4676 - val_accuracy: 0.3850 - val_precision: 0.3828 - val_recall: 0.3510 - val_f1: 0.3658\n",
      "Epoch 32/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 1.8711 - accuracy: 0.9112 - precision: 0.9170 - recall: 0.8956 - f1: 0.9058 - val_loss: 3.3742 - val_accuracy: 0.3800 - val_precision: 0.3780 - val_recall: 0.3510 - val_f1: 0.3636\n",
      "Epoch 33/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 1.7051 - accuracy: 0.9476 - precision: 0.9555 - recall: 0.9304 - f1: 0.9424 - val_loss: 3.3163 - val_accuracy: 0.4050 - val_precision: 0.4196 - val_recall: 0.3990 - val_f1: 0.4088\n",
      "Epoch 34/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 1.5941 - accuracy: 0.9514 - precision: 0.9567 - recall: 0.9371 - f1: 0.9465 - val_loss: 3.1968 - val_accuracy: 0.3600 - val_precision: 0.3756 - val_recall: 0.3510 - val_f1: 0.3623\n",
      "Epoch 35/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 1.5158 - accuracy: 0.9348 - precision: 0.9497 - recall: 0.9206 - f1: 0.9346 - val_loss: 3.1407 - val_accuracy: 0.3700 - val_precision: 0.3934 - val_recall: 0.3702 - val_f1: 0.3808\n",
      "Epoch 36/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 1.4268 - accuracy: 0.9559 - precision: 0.9653 - recall: 0.9482 - f1: 0.9564 - val_loss: 3.0682 - val_accuracy: 0.3500 - val_precision: 0.3692 - val_recall: 0.3413 - val_f1: 0.3544\n",
      "Epoch 37/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 1.3539 - accuracy: 0.9381 - precision: 0.9463 - recall: 0.9311 - f1: 0.9384 - val_loss: 3.0995 - val_accuracy: 0.3700 - val_precision: 0.3666 - val_recall: 0.3413 - val_f1: 0.3531\n",
      "Epoch 38/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 1.3027 - accuracy: 0.9394 - precision: 0.9534 - recall: 0.9306 - f1: 0.9415 - val_loss: 3.2365 - val_accuracy: 0.3850 - val_precision: 0.3753 - val_recall: 0.3510 - val_f1: 0.3619\n",
      "Epoch 39/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 1.2213 - accuracy: 0.9540 - precision: 0.9612 - recall: 0.9447 - f1: 0.9526 - val_loss: 3.1911 - val_accuracy: 0.3800 - val_precision: 0.3825 - val_recall: 0.3606 - val_f1: 0.3707\n",
      "Epoch 40/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 1.1686 - accuracy: 0.9443 - precision: 0.9510 - recall: 0.9369 - f1: 0.9437 - val_loss: 3.0497 - val_accuracy: 0.3600 - val_precision: 0.3713 - val_recall: 0.3558 - val_f1: 0.3633\n",
      "Epoch 41/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 1.1269 - accuracy: 0.9501 - precision: 0.9585 - recall: 0.9403 - f1: 0.9489 - val_loss: 3.1642 - val_accuracy: 0.3350 - val_precision: 0.3375 - val_recall: 0.3269 - val_f1: 0.3321\n",
      "Epoch 42/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 1.0623 - accuracy: 0.9522 - precision: 0.9591 - recall: 0.9407 - f1: 0.9496 - val_loss: 3.1732 - val_accuracy: 0.3500 - val_precision: 0.3548 - val_recall: 0.3413 - val_f1: 0.3477\n",
      "Epoch 43/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 1.0186 - accuracy: 0.9595 - precision: 0.9615 - recall: 0.9464 - f1: 0.9537 - val_loss: 3.2034 - val_accuracy: 0.3600 - val_precision: 0.3545 - val_recall: 0.3413 - val_f1: 0.3476\n",
      "Epoch 44/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 0.9766 - accuracy: 0.9613 - precision: 0.9668 - recall: 0.9552 - f1: 0.9607 - val_loss: 2.9485 - val_accuracy: 0.4000 - val_precision: 0.4090 - val_recall: 0.3846 - val_f1: 0.3962\n",
      "Epoch 45/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 0.9554 - accuracy: 0.9487 - precision: 0.9526 - recall: 0.9423 - f1: 0.9473 - val_loss: 3.3839 - val_accuracy: 0.3100 - val_precision: 0.3048 - val_recall: 0.2981 - val_f1: 0.3013\n",
      "Epoch 46/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 0.9049 - accuracy: 0.9624 - precision: 0.9657 - recall: 0.9542 - f1: 0.9597 - val_loss: 3.1851 - val_accuracy: 0.3750 - val_precision: 0.3830 - val_recall: 0.3654 - val_f1: 0.3737\n",
      "Epoch 47/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 0.8435 - accuracy: 0.9687 - precision: 0.9719 - recall: 0.9650 - f1: 0.9683 - val_loss: 3.1791 - val_accuracy: 0.3800 - val_precision: 0.3777 - val_recall: 0.3702 - val_f1: 0.3738\n",
      "Epoch 48/48\n",
      "112/112 [==============================] - 17s 152ms/step - loss: 0.7993 - accuracy: 0.9750 - precision: 0.9767 - recall: 0.9678 - f1: 0.9721 - val_loss: 3.2933 - val_accuracy: 0.3700 - val_precision: 0.3750 - val_recall: 0.3654 - val_f1: 0.3699\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_imp (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "densenet121 (Functional)        (None, None, None, 1 7037504     img_imp[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bert_input_id (InputLayer)      [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_mask_id (InputLayer)       [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_seg_id (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50176)        0           densenet121[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   bert_input_id[0][0]              \n",
      "                                                                 bert_mask_id[0][0]               \n",
      "                                                                 bert_seg_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         51381248    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 768)          0           tf_bert_model[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          131200      dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          98432       global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           dropout_41[0][0]                 \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           16448       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 64)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 3)            195         dropout_42[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 168,147,267\n",
      "Trainable params: 51,627,523\n",
      "Non-trainable params: 116,519,744\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0umdzW6awppC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lsGO97fCLisk"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/MTL782-Memes Classifier/data_train.pkl\" \"./\"\n",
    "!cp \"/content/drive/MyDrive/MTL782-Memes Classifier/data_test.pkl\" \"./\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 655495,
     "status": "ok",
     "timestamp": 1618150219762,
     "user": {
      "displayName": "Subhalingam D",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64",
      "userId": "08059846138458314824"
     },
     "user_tz": -330
    },
    "id": "r6sVnuyjLkeG",
    "outputId": "d31175be-0482-4465-83f5-de58213a031d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-11 13:59:25.167302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 13:59:29.998816: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-11 13:59:30.004291: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-11 13:59:30.016104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:59:30.016635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-04-11 13:59:30.016668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 13:59:30.028037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 13:59:30.028109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-11 13:59:30.037866: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-11 13:59:30.039282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-11 13:59:30.043169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-11 13:59:30.048486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-11 13:59:30.052234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-11 13:59:30.052352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:59:30.052924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:59:30.054031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-11 13:59:30.054422: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-11 13:59:30.054529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:59:30.055038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-04-11 13:59:30.055067: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 13:59:30.055101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 13:59:30.055123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-11 13:59:30.055145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-11 13:59:30.055166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-11 13:59:30.055184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-11 13:59:30.055204: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-11 13:59:30.055225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-11 13:59:30.055286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:59:30.055798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:59:30.056297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-11 13:59:30.056345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 13:59:30.576115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-11 13:59:30.576171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-04-11 13:59:30.576191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-04-11 13:59:30.576382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:59:30.576988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:59:30.577520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 13:59:30.577993: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-04-11 13:59:30.578046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12675 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_imp (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, None, None, 5 20024384    img_imp[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "text (InputLayer)               [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 25088)        0           vgg19[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 200)      1067000     text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2742)         68794038    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          467968      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          702208      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          32896       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 384)          0           dropout_1[0][0]                  \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           24640       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            195         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 91,113,329\n",
      "Trainable params: 70,021,945\n",
      "Non-trainable params: 21,091,384\n",
      "__________________________________________________________________________________________________\n",
      "tcmalloc: large alloc 1198809088 bytes == 0x5596c55fa000 @  0x7fd54ab5d1e7 0x7fd520a3646e 0x7fd520a86c7b 0x7fd520a89e83 0x7fd520a8a07b 0x7fd520b2b761 0x55964c65d0e4 0x55964c65cde0 0x55964c6d16f5 0x55964c6cbb0e 0x55964c65e77a 0x55964c6d0e50 0x55964c6cbb0e 0x55964c65e77a 0x55964c6ccc9e 0x55964c6cbb0e 0x55964c6cb813 0x55964c795592 0x55964c79590d 0x55964c7957b6 0x55964c76d103 0x55964c76cdac 0x7fd549947bf7 0x55964c76cc8a\n",
      "2021-04-11 14:00:07.561232: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-04-11 14:00:07.577797: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
      "Epoch 1/48\n",
      "2021-04-11 14:00:09.675252: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 19267584 exceeds 10% of free system memory.\n",
      "2021-04-11 14:00:09.675335: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 19267584 exceeds 10% of free system memory.\n",
      "2021-04-11 14:00:09.686087: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 19267584 exceeds 10% of free system memory.\n",
      "2021-04-11 14:00:09.702966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 14:00:10.324450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-11 14:00:10.409032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      " 1/50 [..............................] - ETA: 31:46 - loss: 1.0693 - accuracy: 0.3750 - precision: 0.3333 - recall: 0.1250 - f1: 0.18182021-04-11 14:00:46.567483: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 19267584 exceeds 10% of free system memory.\n",
      " 2/50 [>.............................] - ETA: 8s - loss: 1.1248 - accuracy: 0.3594 - precision: 0.2857 - recall: 0.1094 - f1: 0.1581   2021-04-11 14:00:46.754022: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 19267584 exceeds 10% of free system memory.\n",
      "50/50 [==============================] - 60s 424ms/step - loss: 1.1636 - accuracy: 0.3589 - precision: 0.3547 - recall: 0.1238 - f1: nan - val_loss: 1.0979 - val_accuracy: 0.3835 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 2/48\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 1.1082 - accuracy: 0.4184 - precision: 0.4102 - recall: 0.0895 - f1: nan - val_loss: 1.1624 - val_accuracy: 0.2531 - val_precision: 0.1154 - val_recall: 0.0048 - val_f1: nan\n",
      "Epoch 3/48\n",
      "50/50 [==============================] - 11s 225ms/step - loss: 1.0478 - accuracy: 0.4533 - precision: 0.5736 - recall: 0.1071 - f1: nan - val_loss: 1.0998 - val_accuracy: 0.3910 - val_precision: 0.4615 - val_recall: 0.0340 - val_f1: nan\n",
      "Epoch 4/48\n",
      "50/50 [==============================] - 11s 222ms/step - loss: 1.0347 - accuracy: 0.4546 - precision: 0.5365 - recall: 0.1614 - f1: 0.2450 - val_loss: 1.1181 - val_accuracy: 0.3659 - val_precision: 0.4103 - val_recall: 0.0312 - val_f1: nan\n",
      "Epoch 5/48\n",
      "50/50 [==============================] - 11s 221ms/step - loss: 0.9803 - accuracy: 0.4861 - precision: 0.6182 - recall: 0.2249 - f1: 0.3254 - val_loss: 1.1133 - val_accuracy: 0.3659 - val_precision: 0.5532 - val_recall: 0.1308 - val_f1: 0.2094\n",
      "Epoch 6/48\n",
      "50/50 [==============================] - 11s 224ms/step - loss: 0.9231 - accuracy: 0.5787 - precision: 0.7147 - recall: 0.3059 - f1: 0.4250 - val_loss: 1.1726 - val_accuracy: 0.3183 - val_precision: 0.3911 - val_recall: 0.1205 - val_f1: 0.1810\n",
      "Epoch 7/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.8348 - accuracy: 0.6369 - precision: 0.7572 - recall: 0.4022 - f1: 0.5214 - val_loss: 1.1462 - val_accuracy: 0.3534 - val_precision: 0.3701 - val_recall: 0.1232 - val_f1: 0.1802\n",
      "Epoch 8/48\n",
      "50/50 [==============================] - 11s 227ms/step - loss: 0.7661 - accuracy: 0.6776 - precision: 0.7863 - recall: 0.5090 - f1: 0.6162 - val_loss: 1.1720 - val_accuracy: 0.4110 - val_precision: 0.4355 - val_recall: 0.2447 - val_f1: 0.3087\n",
      "Epoch 9/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.7053 - accuracy: 0.7129 - precision: 0.8102 - recall: 0.5847 - f1: 0.6769 - val_loss: 1.2513 - val_accuracy: 0.3584 - val_precision: 0.2984 - val_recall: 0.1542 - val_f1: 0.2025\n",
      "Epoch 10/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.6287 - accuracy: 0.7636 - precision: 0.8342 - recall: 0.6592 - f1: 0.7350 - val_loss: 1.1950 - val_accuracy: 0.3684 - val_precision: 0.3990 - val_recall: 0.2447 - val_f1: 0.2991\n",
      "Epoch 11/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.5367 - accuracy: 0.8140 - precision: 0.8829 - recall: 0.7455 - f1: 0.8073 - val_loss: 1.2880 - val_accuracy: 0.3684 - val_precision: 0.3779 - val_recall: 0.2588 - val_f1: 0.3052\n",
      "Epoch 12/48\n",
      "50/50 [==============================] - 11s 225ms/step - loss: 0.4834 - accuracy: 0.8184 - precision: 0.8809 - recall: 0.7539 - f1: 0.8117 - val_loss: 1.2637 - val_accuracy: 0.3885 - val_precision: 0.3904 - val_recall: 0.2567 - val_f1: 0.3072\n",
      "Epoch 13/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.4006 - accuracy: 0.8783 - precision: 0.9134 - recall: 0.8264 - f1: 0.8669 - val_loss: 1.3053 - val_accuracy: 0.3985 - val_precision: 0.4148 - val_recall: 0.2976 - val_f1: 0.3449\n",
      "Epoch 14/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.3364 - accuracy: 0.9165 - precision: 0.9364 - recall: 0.8767 - f1: 0.9053 - val_loss: 1.4206 - val_accuracy: 0.3684 - val_precision: 0.3513 - val_recall: 0.2756 - val_f1: 0.3084\n",
      "Epoch 15/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.2737 - accuracy: 0.9387 - precision: 0.9568 - recall: 0.9149 - f1: 0.9350 - val_loss: 1.4936 - val_accuracy: 0.3509 - val_precision: 0.3522 - val_recall: 0.2832 - val_f1: 0.3130\n",
      "Epoch 16/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.2457 - accuracy: 0.9414 - precision: 0.9562 - recall: 0.9240 - f1: 0.9396 - val_loss: 1.5331 - val_accuracy: 0.3960 - val_precision: 0.3864 - val_recall: 0.3264 - val_f1: 0.3536\n",
      "Epoch 17/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.2057 - accuracy: 0.9612 - precision: 0.9696 - recall: 0.9354 - f1: 0.9518 - val_loss: 1.6033 - val_accuracy: 0.3885 - val_precision: 0.4014 - val_recall: 0.3333 - val_f1: 0.3632\n",
      "Epoch 18/48\n",
      "50/50 [==============================] - 11s 225ms/step - loss: 0.1734 - accuracy: 0.9680 - precision: 0.9792 - recall: 0.9482 - f1: 0.9631 - val_loss: 1.6526 - val_accuracy: 0.3860 - val_precision: 0.3823 - val_recall: 0.3261 - val_f1: 0.3515\n",
      "Epoch 19/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.1369 - accuracy: 0.9781 - precision: 0.9803 - recall: 0.9692 - f1: 0.9746 - val_loss: 1.6724 - val_accuracy: 0.3759 - val_precision: 0.3889 - val_recall: 0.3285 - val_f1: 0.3557\n",
      "Epoch 20/48\n",
      "50/50 [==============================] - 11s 225ms/step - loss: 0.1316 - accuracy: 0.9718 - precision: 0.9748 - recall: 0.9654 - f1: 0.9700 - val_loss: 1.7921 - val_accuracy: 0.3709 - val_precision: 0.3627 - val_recall: 0.3255 - val_f1: 0.3430\n",
      "Epoch 21/48\n",
      "50/50 [==============================] - 11s 225ms/step - loss: 0.1194 - accuracy: 0.9775 - precision: 0.9841 - recall: 0.9730 - f1: 0.9784 - val_loss: 1.7482 - val_accuracy: 0.3885 - val_precision: 0.3943 - val_recall: 0.3529 - val_f1: 0.3722\n",
      "Epoch 22/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.1207 - accuracy: 0.9757 - precision: 0.9822 - recall: 0.9708 - f1: 0.9764 - val_loss: 1.7620 - val_accuracy: 0.3935 - val_precision: 0.4019 - val_recall: 0.3556 - val_f1: 0.3768\n",
      "Epoch 23/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0693 - accuracy: 0.9934 - precision: 0.9945 - recall: 0.9908 - f1: 0.9926 - val_loss: 1.9792 - val_accuracy: 0.3784 - val_precision: 0.3806 - val_recall: 0.3532 - val_f1: 0.3662\n",
      "Epoch 24/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0537 - accuracy: 0.9956 - precision: 0.9967 - recall: 0.9941 - f1: 0.9954 - val_loss: 2.0381 - val_accuracy: 0.3459 - val_precision: 0.3649 - val_recall: 0.3381 - val_f1: 0.3508\n",
      "Epoch 25/48\n",
      "50/50 [==============================] - 11s 225ms/step - loss: 0.0573 - accuracy: 0.9867 - precision: 0.9873 - recall: 0.9864 - f1: 0.9869 - val_loss: 2.0262 - val_accuracy: 0.3684 - val_precision: 0.3808 - val_recall: 0.3529 - val_f1: 0.3661\n",
      "Epoch 26/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0520 - accuracy: 0.9947 - precision: 0.9946 - recall: 0.9934 - f1: 0.9940 - val_loss: 1.9741 - val_accuracy: 0.4010 - val_precision: 0.3994 - val_recall: 0.3670 - val_f1: 0.3820\n",
      "Epoch 27/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0510 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - f1: 0.9950 - val_loss: 2.0443 - val_accuracy: 0.3960 - val_precision: 0.3947 - val_recall: 0.3619 - val_f1: 0.3771\n",
      "Epoch 28/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0359 - accuracy: 0.9983 - precision: 0.9983 - recall: 0.9980 - f1: 0.9981 - val_loss: 2.1095 - val_accuracy: 0.3784 - val_precision: 0.3879 - val_recall: 0.3550 - val_f1: 0.3703\n",
      "Epoch 29/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0326 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9970 - f1: 0.9972 - val_loss: 2.0569 - val_accuracy: 0.3860 - val_precision: 0.3866 - val_recall: 0.3574 - val_f1: 0.3710\n",
      "Epoch 30/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0363 - accuracy: 0.9956 - precision: 0.9965 - recall: 0.9942 - f1: 0.9953 - val_loss: 2.1229 - val_accuracy: 0.3835 - val_precision: 0.3896 - val_recall: 0.3574 - val_f1: 0.3725\n",
      "Epoch 31/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0284 - accuracy: 0.9977 - precision: 0.9980 - recall: 0.9977 - f1: 0.9978 - val_loss: 2.1686 - val_accuracy: 0.3784 - val_precision: 0.3814 - val_recall: 0.3574 - val_f1: 0.3689\n",
      "Epoch 32/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0273 - accuracy: 0.9984 - precision: 0.9990 - recall: 0.9973 - f1: 0.9981 - val_loss: 2.1575 - val_accuracy: 0.3935 - val_precision: 0.3954 - val_recall: 0.3721 - val_f1: 0.3832\n",
      "Epoch 33/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0220 - accuracy: 0.9979 - precision: 0.9979 - recall: 0.9979 - f1: 0.9979 - val_loss: 2.2157 - val_accuracy: 0.3810 - val_precision: 0.3895 - val_recall: 0.3646 - val_f1: 0.3765\n",
      "Epoch 34/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0187 - accuracy: 0.9990 - precision: 0.9990 - recall: 0.9985 - f1: 0.9987 - val_loss: 2.3533 - val_accuracy: 0.3810 - val_precision: 0.3797 - val_recall: 0.3574 - val_f1: 0.3680\n",
      "Epoch 35/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0195 - accuracy: 0.9983 - precision: 0.9991 - recall: 0.9983 - f1: 0.9987 - val_loss: 2.2117 - val_accuracy: 0.3810 - val_precision: 0.3982 - val_recall: 0.3694 - val_f1: 0.3829\n",
      "Epoch 36/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0159 - accuracy: 0.9994 - precision: 0.9994 - recall: 0.9994 - f1: 0.9994 - val_loss: 2.2754 - val_accuracy: 0.3759 - val_precision: 0.3831 - val_recall: 0.3574 - val_f1: 0.3695\n",
      "Epoch 37/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0212 - accuracy: 0.9983 - precision: 0.9983 - recall: 0.9983 - f1: 0.9983 - val_loss: 2.3735 - val_accuracy: 0.3810 - val_precision: 0.3843 - val_recall: 0.3673 - val_f1: 0.3755\n",
      "Epoch 38/48\n",
      "50/50 [==============================] - 11s 225ms/step - loss: 0.0264 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - f1: 0.9972 - val_loss: 2.3645 - val_accuracy: 0.3860 - val_precision: 0.3935 - val_recall: 0.3694 - val_f1: 0.3808\n",
      "Epoch 39/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0126 - accuracy: 0.9982 - precision: 0.9982 - recall: 0.9982 - f1: 0.9982 - val_loss: 2.3709 - val_accuracy: 0.3935 - val_precision: 0.3996 - val_recall: 0.3817 - val_f1: 0.3903\n",
      "Epoch 40/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0168 - accuracy: 0.9987 - precision: 0.9987 - recall: 0.9987 - f1: 0.9987 - val_loss: 2.3465 - val_accuracy: 0.3910 - val_precision: 0.3850 - val_recall: 0.3622 - val_f1: 0.3731\n",
      "Epoch 41/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0153 - accuracy: 0.9981 - precision: 0.9981 - recall: 0.9981 - f1: 0.9981 - val_loss: 2.4090 - val_accuracy: 0.3784 - val_precision: 0.3829 - val_recall: 0.3526 - val_f1: 0.3669\n",
      "Epoch 42/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0178 - accuracy: 0.9975 - precision: 0.9979 - recall: 0.9975 - f1: 0.9977 - val_loss: 2.3888 - val_accuracy: 0.4010 - val_precision: 0.3985 - val_recall: 0.3790 - val_f1: 0.3884\n",
      "Epoch 43/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0095 - accuracy: 0.9998 - precision: 0.9998 - recall: 0.9998 - f1: 0.9998 - val_loss: 2.4359 - val_accuracy: 0.3885 - val_precision: 0.3877 - val_recall: 0.3742 - val_f1: 0.3807\n",
      "Epoch 44/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0121 - accuracy: 0.9969 - precision: 0.9969 - recall: 0.9969 - f1: 0.9969 - val_loss: 2.4513 - val_accuracy: 0.3810 - val_precision: 0.3792 - val_recall: 0.3646 - val_f1: 0.3717\n",
      "Epoch 45/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0111 - accuracy: 0.9977 - precision: 0.9977 - recall: 0.9977 - f1: 0.9977 - val_loss: 2.4951 - val_accuracy: 0.3709 - val_precision: 0.3725 - val_recall: 0.3495 - val_f1: 0.3604\n",
      "Epoch 46/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0242 - accuracy: 0.9960 - precision: 0.9966 - recall: 0.9960 - f1: 0.9963 - val_loss: 2.4106 - val_accuracy: 0.4010 - val_precision: 0.4040 - val_recall: 0.3865 - val_f1: 0.3949\n",
      "Epoch 47/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0140 - accuracy: 0.9981 - precision: 0.9981 - recall: 0.9981 - f1: 0.9981 - val_loss: 2.5355 - val_accuracy: 0.3835 - val_precision: 0.3928 - val_recall: 0.3745 - val_f1: 0.3832\n",
      "Epoch 48/48\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 0.0094 - accuracy: 0.9989 - precision: 0.9989 - recall: 0.9989 - f1: 0.9989 - val_loss: 2.5307 - val_accuracy: 0.3759 - val_precision: 0.3797 - val_recall: 0.3697 - val_f1: 0.3745\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## SUB4\n",
    "!python train2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hMwCczeN2wx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDxR76y7Qm9y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrmRZxuDQnNU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_u01T9P2Qnem"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 601377,
     "status": "ok",
     "timestamp": 1618151882349,
     "user": {
      "displayName": "Subhalingam D",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64",
      "userId": "08059846138458314824"
     },
     "user_tz": -330
    },
    "id": "wHeP2qlCQn7h",
    "outputId": "9467e899-d661-4b11-fa9c-68fa302b35c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-11 14:28:01.767665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 14:28:05.087895: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-11 14:28:05.093308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-11 14:28:05.103820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 14:28:05.104351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-04-11 14:28:05.104386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 14:28:05.118132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 14:28:05.118208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-11 14:28:05.123291: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-11 14:28:05.128342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-11 14:28:05.136966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-11 14:28:05.138547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-11 14:28:05.139136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-11 14:28:05.139247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 14:28:05.139786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 14:28:05.140282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-11 14:28:05.140677: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-11 14:28:05.140793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 14:28:05.141328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-04-11 14:28:05.141362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 14:28:05.141404: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 14:28:05.141426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-11 14:28:05.141447: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-11 14:28:05.141469: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-11 14:28:05.141488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-11 14:28:05.141507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-11 14:28:05.141527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-11 14:28:05.141592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 14:28:05.142132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 14:28:05.142586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-11 14:28:05.142631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-11 14:28:05.658019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-11 14:28:05.658074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-04-11 14:28:05.658097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-04-11 14:28:05.658305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 14:28:05.658928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 14:28:05.659453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-11 14:28:05.659933: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-04-11 14:28:05.659985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12675 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_imp (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, None, None, 5 20024384    img_imp[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           vgg19[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "text (InputLayer)               [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 200)      1067000     text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          467968      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          65664       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          32896       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           dropout_2[0][0]                  \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           16448       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            195         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,676,603\n",
      "Trainable params: 584,195\n",
      "Non-trainable params: 21,092,408\n",
      "__________________________________________________________________________________________________\n",
      "tcmalloc: large alloc 1198809088 bytes == 0x55789411a000 @  0x7f48941db1e7 0x7f486a0f446e 0x7f486a144c7b 0x7f486a147e83 0x7f486a14807b 0x7f486a1e9761 0x55781ae300e4 0x55781ae2fde0 0x55781aea46f5 0x55781ae9eb0e 0x55781ae3177a 0x55781aea3e50 0x55781ae9eb0e 0x55781ae3177a 0x55781ae9fc9e 0x55781ae9eb0e 0x55781ae9e813 0x55781af68592 0x55781af6890d 0x55781af687b6 0x55781af40103 0x55781af3fdac 0x7f4892fc5bf7 0x55781af3fc8a\n",
      "2021-04-11 14:28:32.503277: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-04-11 14:28:32.503718: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
      "Epoch 1/48\n",
      "2021-04-11 14:28:34.684238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-11 14:28:35.211768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-11 14:28:35.230365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "50/50 [==============================] - 57s 409ms/step - loss: 1.5164 - accuracy: 0.3033 - precision: 0.2876 - recall: 0.2057 - f1: 0.2392 - val_loss: 1.1524 - val_accuracy: 0.2707 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 2/48\n",
      "50/50 [==============================] - 11s 218ms/step - loss: 1.4449 - accuracy: 0.3335 - precision: 0.3229 - recall: 0.2263 - f1: 0.2655 - val_loss: 1.1269 - val_accuracy: 0.2757 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 3/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.4180 - accuracy: 0.3202 - precision: 0.3046 - recall: 0.2002 - f1: 0.2408 - val_loss: 1.1127 - val_accuracy: 0.2657 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 4/48\n",
      "50/50 [==============================] - 10s 207ms/step - loss: 1.3430 - accuracy: 0.3247 - precision: 0.3153 - recall: 0.2145 - f1: 0.2542 - val_loss: 1.1066 - val_accuracy: 0.3208 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 5/48\n",
      "50/50 [==============================] - 10s 207ms/step - loss: 1.3530 - accuracy: 0.3366 - precision: 0.3271 - recall: 0.2128 - f1: 0.2570 - val_loss: 1.1053 - val_accuracy: 0.3308 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 6/48\n",
      "50/50 [==============================] - 10s 208ms/step - loss: 1.2991 - accuracy: 0.3594 - precision: 0.3565 - recall: 0.2183 - f1: 0.2694 - val_loss: 1.1100 - val_accuracy: 0.3434 - val_precision: 0.0769 - val_recall: 0.0024 - val_f1: nan\n",
      "Epoch 7/48\n",
      "50/50 [==============================] - 10s 210ms/step - loss: 1.2900 - accuracy: 0.3568 - precision: 0.3551 - recall: 0.2136 - f1: 0.2656 - val_loss: 1.1207 - val_accuracy: 0.3108 - val_precision: 0.3718 - val_recall: 0.0192 - val_f1: nan\n",
      "Epoch 8/48\n",
      "50/50 [==============================] - 11s 212ms/step - loss: 1.2721 - accuracy: 0.3575 - precision: 0.3807 - recall: 0.2200 - f1: 0.2777 - val_loss: 1.1266 - val_accuracy: 0.3208 - val_precision: 0.4256 - val_recall: 0.0216 - val_f1: nan\n",
      "Epoch 9/48\n",
      "50/50 [==============================] - 11s 213ms/step - loss: 1.2665 - accuracy: 0.3544 - precision: 0.3703 - recall: 0.2096 - f1: 0.2665 - val_loss: 1.1428 - val_accuracy: 0.3333 - val_precision: 0.3683 - val_recall: 0.0433 - val_f1: nan\n",
      "Epoch 10/48\n",
      "50/50 [==============================] - 11s 212ms/step - loss: 1.2738 - accuracy: 0.3245 - precision: 0.3377 - recall: 0.1932 - f1: 0.2450 - val_loss: 1.1399 - val_accuracy: 0.3183 - val_precision: 0.3348 - val_recall: 0.0264 - val_f1: nan\n",
      "Epoch 11/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.3009 - accuracy: 0.3256 - precision: 0.3490 - recall: 0.1929 - f1: 0.2475 - val_loss: 1.1376 - val_accuracy: 0.3083 - val_precision: 0.4769 - val_recall: 0.0268 - val_f1: nan\n",
      "Epoch 12/48\n",
      "50/50 [==============================] - 10s 210ms/step - loss: 1.2132 - accuracy: 0.3900 - precision: 0.3693 - recall: 0.2075 - f1: 0.2649 - val_loss: 1.1314 - val_accuracy: 0.3108 - val_precision: 0.4808 - val_recall: 0.0268 - val_f1: nan\n",
      "Epoch 13/48\n",
      "50/50 [==============================] - 10s 210ms/step - loss: 1.2531 - accuracy: 0.3183 - precision: 0.3393 - recall: 0.1789 - f1: 0.2330 - val_loss: 1.1287 - val_accuracy: 0.3133 - val_precision: 0.5064 - val_recall: 0.0244 - val_f1: nan\n",
      "Epoch 14/48\n",
      "50/50 [==============================] - 10s 211ms/step - loss: 1.1837 - accuracy: 0.3879 - precision: 0.3793 - recall: 0.1995 - f1: 0.2603 - val_loss: 1.1250 - val_accuracy: 0.3233 - val_precision: 0.4808 - val_recall: 0.0220 - val_f1: nan\n",
      "Epoch 15/48\n",
      "50/50 [==============================] - 10s 210ms/step - loss: 1.2083 - accuracy: 0.3543 - precision: 0.3697 - recall: 0.1924 - f1: nan - val_loss: 1.1249 - val_accuracy: 0.3158 - val_precision: 0.3846 - val_recall: 0.0171 - val_f1: nan\n",
      "Epoch 16/48\n",
      "50/50 [==============================] - 10s 210ms/step - loss: 1.2054 - accuracy: 0.3402 - precision: 0.3397 - recall: 0.1689 - f1: 0.2242 - val_loss: 1.1280 - val_accuracy: 0.3233 - val_precision: 0.2692 - val_recall: 0.0123 - val_f1: nan\n",
      "Epoch 17/48\n",
      "50/50 [==============================] - 10s 211ms/step - loss: 1.2394 - accuracy: 0.3500 - precision: 0.3637 - recall: 0.1762 - f1: 0.2361 - val_loss: 1.1234 - val_accuracy: 0.3108 - val_precision: 0.1923 - val_recall: 0.0099 - val_f1: nan\n",
      "Epoch 18/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.2196 - accuracy: 0.3589 - precision: 0.3421 - recall: 0.1603 - f1: 0.2162 - val_loss: 1.1200 - val_accuracy: 0.3183 - val_precision: 0.1538 - val_recall: 0.0075 - val_f1: nan\n",
      "Epoch 19/48\n",
      "50/50 [==============================] - 11s 212ms/step - loss: 1.2530 - accuracy: 0.3130 - precision: 0.3140 - recall: 0.1458 - f1: 0.1978 - val_loss: 1.1234 - val_accuracy: 0.2982 - val_precision: 0.2308 - val_recall: 0.0099 - val_f1: nan\n",
      "Epoch 20/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1865 - accuracy: 0.3405 - precision: 0.3842 - recall: 0.1648 - f1: 0.2288 - val_loss: 1.1223 - val_accuracy: 0.3108 - val_precision: 0.2308 - val_recall: 0.0099 - val_f1: nan\n",
      "Epoch 21/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1943 - accuracy: 0.3544 - precision: 0.3572 - recall: 0.1452 - f1: 0.2049 - val_loss: 1.1167 - val_accuracy: 0.2882 - val_precision: 0.2308 - val_recall: 0.0099 - val_f1: nan\n",
      "Epoch 22/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1955 - accuracy: 0.3765 - precision: 0.3760 - recall: 0.1518 - f1: nan - val_loss: 1.1139 - val_accuracy: 0.3033 - val_precision: 0.1538 - val_recall: 0.0075 - val_f1: nan\n",
      "Epoch 23/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1580 - accuracy: 0.3708 - precision: 0.3787 - recall: 0.1423 - f1: 0.2042 - val_loss: 1.1139 - val_accuracy: 0.2982 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 24/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1531 - accuracy: 0.3863 - precision: 0.4346 - recall: 0.1670 - f1: 0.2387 - val_loss: 1.1101 - val_accuracy: 0.3058 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 25/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1527 - accuracy: 0.3566 - precision: 0.4223 - recall: 0.1634 - f1: 0.2340 - val_loss: 1.1086 - val_accuracy: 0.3108 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 26/48\n",
      "50/50 [==============================] - 10s 211ms/step - loss: 1.1927 - accuracy: 0.3298 - precision: 0.3433 - recall: 0.1319 - f1: 0.1882 - val_loss: 1.1090 - val_accuracy: 0.3133 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 27/48\n",
      "50/50 [==============================] - 11s 212ms/step - loss: 1.1602 - accuracy: 0.3671 - precision: 0.4115 - recall: 0.1509 - f1: 0.2186 - val_loss: 1.1082 - val_accuracy: 0.3158 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 28/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1835 - accuracy: 0.3572 - precision: 0.3349 - recall: 0.1228 - f1: 0.1776 - val_loss: 1.1097 - val_accuracy: 0.3108 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 29/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1622 - accuracy: 0.3584 - precision: 0.3752 - recall: 0.1241 - f1: 0.1848 - val_loss: 1.1070 - val_accuracy: 0.3233 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 30/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1531 - accuracy: 0.3630 - precision: 0.3557 - recall: 0.1154 - f1: 0.1731 - val_loss: 1.1085 - val_accuracy: 0.3158 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 31/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1584 - accuracy: 0.3496 - precision: 0.3380 - recall: 0.1189 - f1: 0.1745 - val_loss: 1.1096 - val_accuracy: 0.3158 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 32/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1574 - accuracy: 0.3566 - precision: 0.3882 - recall: 0.1460 - f1: nan - val_loss: 1.1069 - val_accuracy: 0.3233 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 33/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1894 - accuracy: 0.3210 - precision: 0.3036 - recall: 0.1029 - f1: nan - val_loss: 1.1072 - val_accuracy: 0.3183 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 34/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1673 - accuracy: 0.3493 - precision: 0.3669 - recall: 0.1245 - f1: 0.1839 - val_loss: 1.1070 - val_accuracy: 0.3183 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 35/48\n",
      "50/50 [==============================] - 10s 211ms/step - loss: 1.1673 - accuracy: 0.3352 - precision: 0.3710 - recall: 0.1213 - f1: 0.1807 - val_loss: 1.1075 - val_accuracy: 0.3083 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 36/48\n",
      "50/50 [==============================] - 10s 211ms/step - loss: 1.1533 - accuracy: 0.3418 - precision: 0.3613 - recall: 0.1254 - f1: 0.1849 - val_loss: 1.1062 - val_accuracy: 0.3208 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 37/48\n",
      "50/50 [==============================] - 10s 211ms/step - loss: 1.1476 - accuracy: 0.3703 - precision: 0.3423 - recall: 0.1178 - f1: 0.1731 - val_loss: 1.1053 - val_accuracy: 0.3208 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 38/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1562 - accuracy: 0.3581 - precision: 0.3619 - recall: 0.1176 - f1: 0.1752 - val_loss: 1.1058 - val_accuracy: 0.2982 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 39/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1619 - accuracy: 0.3641 - precision: 0.3984 - recall: 0.1337 - f1: nan - val_loss: 1.1032 - val_accuracy: 0.3158 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 40/48\n",
      "50/50 [==============================] - 10s 211ms/step - loss: 1.1514 - accuracy: 0.3536 - precision: 0.3535 - recall: 0.1219 - f1: nan - val_loss: 1.1042 - val_accuracy: 0.3058 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 41/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1422 - accuracy: 0.3477 - precision: 0.3559 - recall: 0.1099 - f1: nan - val_loss: 1.1032 - val_accuracy: 0.3058 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 42/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1409 - accuracy: 0.3712 - precision: 0.4250 - recall: 0.1303 - f1: 0.1965 - val_loss: 1.1039 - val_accuracy: 0.3033 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 43/48\n",
      "50/50 [==============================] - 10s 211ms/step - loss: 1.1548 - accuracy: 0.3399 - precision: 0.3732 - recall: 0.1145 - f1: nan - val_loss: 1.1031 - val_accuracy: 0.3058 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 44/48\n",
      "50/50 [==============================] - 10s 210ms/step - loss: 1.1307 - accuracy: 0.3585 - precision: 0.4060 - recall: 0.1220 - f1: nan - val_loss: 1.1021 - val_accuracy: 0.3158 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 45/48\n",
      "50/50 [==============================] - 10s 211ms/step - loss: 1.1500 - accuracy: 0.3393 - precision: 0.3422 - recall: 0.1025 - f1: nan - val_loss: 1.1026 - val_accuracy: 0.3158 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 46/48\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 1.1120 - accuracy: 0.3916 - precision: 0.4008 - recall: 0.1079 - f1: nan - val_loss: 1.1025 - val_accuracy: 0.3208 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 47/48\n",
      "50/50 [==============================] - 10s 211ms/step - loss: 1.1487 - accuracy: 0.3626 - precision: 0.3738 - recall: 0.1068 - f1: nan - val_loss: 1.1024 - val_accuracy: 0.3233 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "Epoch 48/48\n",
      "50/50 [==============================] - 10s 211ms/step - loss: 1.1349 - accuracy: 0.3705 - precision: 0.3998 - recall: 0.1177 - f1: nan - val_loss: 1.1026 - val_accuracy: 0.3133 - val_precision: 0.0769 - val_recall: 0.0051 - val_f1: nan\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "!python train2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1029,
     "status": "ok",
     "timestamp": 1618207361401,
     "user": {
      "displayName": "Subhalingam D",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64",
      "userId": "08059846138458314824"
     },
     "user_tz": -330
    },
    "id": "CoZ9mcvSRRo-",
    "outputId": "484a0841-dacf-405a-d56a-f6a7ebd07cb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " glove\t glove.6B.zip  'IMDB Dataset.csv'   tweet_train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/drive/My Drive/colab/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53934,
     "status": "ok",
     "timestamp": 1618207449195,
     "user": {
      "displayName": "Subhalingam D",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64",
      "userId": "08059846138458314824"
     },
     "user_tz": -330
    },
    "id": "TgZ-x0_WrMTL",
    "outputId": "9a96dfaf-4c1b-4b88-ece4-876593154349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/My Drive/colab/data/glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "!unzip \"/content/drive/My Drive/colab/data/glove.6B.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118206,
     "status": "ok",
     "timestamp": 1618207725111,
     "user": {
      "displayName": "Subhalingam D",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64",
      "userId": "08059846138458314824"
     },
     "user_tz": -330
    },
    "id": "YZ4tWp4OrSxb",
    "outputId": "f7c22cd6-3813-4ecc-e18b-918808b50353"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-12 06:06:47.492883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-12 06:07:02.592231: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-12 06:07:02.602382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-12 06:07:02.677455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-12 06:07:02.679796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-04-12 06:07:02.679871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-12 06:07:02.839545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-12 06:07:02.839743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-12 06:07:03.032922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-12 06:07:03.055951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-12 06:07:03.327176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-12 06:07:03.357862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-12 06:07:03.365720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-12 06:07:03.365961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-12 06:07:03.366855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-12 06:07:03.370861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-12 06:07:03.371368: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-12 06:07:03.371546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-12 06:07:03.372291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-04-12 06:07:03.372339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-12 06:07:03.372405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-12 06:07:03.372447: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-12 06:07:03.372483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-12 06:07:03.372557: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-12 06:07:03.372631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-12 06:07:03.372682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-12 06:07:03.372720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-12 06:07:03.372810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-12 06:07:03.373552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-12 06:07:03.374222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-12 06:07:03.377927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-12 06:07:07.658604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-12 06:07:07.658689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-04-12 06:07:07.658720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-04-12 06:07:07.662534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-12 06:07:07.663431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-12 06:07:07.664330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-12 06:07:07.665082: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-04-12 06:07:07.665140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10637 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 50, 100)           533500    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 654,975\n",
      "Trainable params: 121,475\n",
      "Non-trainable params: 533,500\n",
      "_________________________________________________________________\n",
      "2021-04-12 06:07:09.114534: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-04-12 06:07:09.129952: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
      "Epoch 1/64\n",
      "2021-04-12 06:07:11.378811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-12 06:07:13.397906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-12 06:07:13.537301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "56/56 [==============================] - 32s 32ms/step - loss: 1.0985 - accuracy: 0.3666 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 1.0979 - val_accuracy: 0.4500 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 2/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0985 - accuracy: 0.3383 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 1.0983 - val_accuracy: 0.2950 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 3/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0975 - accuracy: 0.3866 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 1.0982 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 4/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0969 - accuracy: 0.3797 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 1.0982 - val_accuracy: 0.4200 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 5/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0969 - accuracy: 0.3668 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 1.0985 - val_accuracy: 0.3900 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 6/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0970 - accuracy: 0.3694 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 1.0984 - val_accuracy: 0.3900 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 7/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0960 - accuracy: 0.3769 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 1.0983 - val_accuracy: 0.4050 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 8/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0964 - accuracy: 0.3702 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 1.0984 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 9/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0944 - accuracy: 0.3710 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 1.0986 - val_accuracy: 0.3950 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 10/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0941 - accuracy: 0.3772 - precision: 0.0080 - recall: 2.4932e-04 - f1: nan - val_loss: 1.0985 - val_accuracy: 0.3900 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 11/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0937 - accuracy: 0.3755 - precision: 0.0190 - recall: 5.9298e-04 - f1: nan - val_loss: 1.0984 - val_accuracy: 0.3900 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 12/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0933 - accuracy: 0.3757 - precision: 0.0209 - recall: 6.5229e-04 - f1: nan - val_loss: 1.0986 - val_accuracy: 0.3800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 13/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0933 - accuracy: 0.3802 - precision: 0.0090 - recall: 2.8022e-04 - f1: nan - val_loss: 1.0984 - val_accuracy: 0.3750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 14/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0915 - accuracy: 0.3694 - precision: 0.0412 - recall: 0.0013 - f1: nan - val_loss: 1.0980 - val_accuracy: 0.3950 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 15/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0906 - accuracy: 0.3872 - precision: 0.0085 - recall: 2.6455e-04 - f1: nan - val_loss: 1.0980 - val_accuracy: 0.3900 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 16/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0913 - accuracy: 0.3778 - precision: 0.0201 - recall: 6.2960e-04 - f1: nan - val_loss: 1.0979 - val_accuracy: 0.3900 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 17/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0907 - accuracy: 0.3839 - precision: 0.1667 - recall: 0.0052 - f1: nan - val_loss: 1.0977 - val_accuracy: 0.3900 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 18/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0928 - accuracy: 0.3674 - precision: 0.1347 - recall: 0.0042 - f1: nan - val_loss: 1.0969 - val_accuracy: 0.3900 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 19/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0908 - accuracy: 0.3758 - precision: 0.1479 - recall: 0.0056 - f1: nan - val_loss: 1.0972 - val_accuracy: 0.4100 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 20/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0872 - accuracy: 0.3967 - precision: 0.2035 - recall: 0.0068 - f1: nan - val_loss: 1.0963 - val_accuracy: 0.3900 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 21/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0903 - accuracy: 0.3878 - precision: 0.1567 - recall: 0.0051 - f1: nan - val_loss: 1.0963 - val_accuracy: 0.3900 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 22/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0897 - accuracy: 0.3986 - precision: 0.1863 - recall: 0.0071 - f1: nan - val_loss: 1.0960 - val_accuracy: 0.4050 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 23/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0863 - accuracy: 0.3775 - precision: 0.4277 - recall: 0.0183 - f1: nan - val_loss: 1.0955 - val_accuracy: 0.4100 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 24/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0845 - accuracy: 0.3854 - precision: 0.3267 - recall: 0.0147 - f1: nan - val_loss: 1.0944 - val_accuracy: 0.4200 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 25/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0873 - accuracy: 0.3805 - precision: 0.2616 - recall: 0.0090 - f1: nan - val_loss: 1.0943 - val_accuracy: 0.4300 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 26/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0841 - accuracy: 0.3987 - precision: 0.3609 - recall: 0.0149 - f1: nan - val_loss: 1.0946 - val_accuracy: 0.4300 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 27/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0838 - accuracy: 0.3788 - precision: 0.3967 - recall: 0.0154 - f1: nan - val_loss: 1.0923 - val_accuracy: 0.4300 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 28/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0851 - accuracy: 0.4044 - precision: 0.2997 - recall: 0.0119 - f1: nan - val_loss: 1.0918 - val_accuracy: 0.4350 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 29/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0790 - accuracy: 0.3995 - precision: 0.4313 - recall: 0.0188 - f1: nan - val_loss: 1.0888 - val_accuracy: 0.4550 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 30/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0822 - accuracy: 0.3923 - precision: 0.3892 - recall: 0.0142 - f1: nan - val_loss: 1.0882 - val_accuracy: 0.4600 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 31/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0770 - accuracy: 0.4045 - precision: 0.4267 - recall: 0.0213 - f1: nan - val_loss: 1.0871 - val_accuracy: 0.4650 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 32/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0786 - accuracy: 0.4021 - precision: 0.4662 - recall: 0.0261 - f1: nan - val_loss: 1.0872 - val_accuracy: 0.4650 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 33/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0810 - accuracy: 0.3734 - precision: 0.5971 - recall: 0.0244 - f1: nan - val_loss: 1.0872 - val_accuracy: 0.4600 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 34/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0757 - accuracy: 0.4276 - precision: 0.4270 - recall: 0.0244 - f1: nan - val_loss: 1.0867 - val_accuracy: 0.4600 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 35/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0770 - accuracy: 0.4176 - precision: 0.4922 - recall: 0.0291 - f1: nan - val_loss: 1.0850 - val_accuracy: 0.4500 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 36/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0743 - accuracy: 0.4037 - precision: 0.6353 - recall: 0.0306 - f1: nan - val_loss: 1.0808 - val_accuracy: 0.4750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 37/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0757 - accuracy: 0.3896 - precision: 0.4024 - recall: 0.0253 - f1: nan - val_loss: 1.0811 - val_accuracy: 0.4750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 38/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0717 - accuracy: 0.4173 - precision: 0.5216 - recall: 0.0261 - f1: nan - val_loss: 1.0833 - val_accuracy: 0.4550 - val_precision: 0.1905 - val_recall: 0.0089 - val_f1: nan\n",
      "Epoch 39/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0720 - accuracy: 0.3903 - precision: 0.5316 - recall: 0.0309 - f1: nan - val_loss: 1.0794 - val_accuracy: 0.4750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 40/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0706 - accuracy: 0.4044 - precision: 0.3960 - recall: 0.0200 - f1: nan - val_loss: 1.0790 - val_accuracy: 0.4700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 41/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0631 - accuracy: 0.4163 - precision: 0.5812 - recall: 0.0360 - f1: nan - val_loss: 1.0776 - val_accuracy: 0.4850 - val_precision: 0.0714 - val_recall: 0.0045 - val_f1: nan\n",
      "Epoch 42/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0629 - accuracy: 0.4211 - precision: 0.5299 - recall: 0.0369 - f1: nan - val_loss: 1.0765 - val_accuracy: 0.4750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 43/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0681 - accuracy: 0.4225 - precision: 0.4134 - recall: 0.0265 - f1: nan - val_loss: 1.0743 - val_accuracy: 0.4700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 44/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0665 - accuracy: 0.4174 - precision: 0.5488 - recall: 0.0298 - f1: nan - val_loss: 1.0744 - val_accuracy: 0.4800 - val_precision: 0.1429 - val_recall: 0.0045 - val_f1: nan\n",
      "Epoch 45/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0614 - accuracy: 0.4132 - precision: 0.6089 - recall: 0.0446 - f1: nan - val_loss: 1.0733 - val_accuracy: 0.4850 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 46/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0583 - accuracy: 0.4201 - precision: 0.6078 - recall: 0.0333 - f1: nan - val_loss: 1.0772 - val_accuracy: 0.4650 - val_precision: 0.4286 - val_recall: 0.0179 - val_f1: nan\n",
      "Epoch 47/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0554 - accuracy: 0.4439 - precision: 0.6734 - recall: 0.0356 - f1: nan - val_loss: 1.0718 - val_accuracy: 0.4800 - val_precision: 0.2619 - val_recall: 0.0134 - val_f1: nan\n",
      "Epoch 48/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0554 - accuracy: 0.4380 - precision: 0.5917 - recall: 0.0413 - f1: nan - val_loss: 1.0710 - val_accuracy: 0.4800 - val_precision: 0.2619 - val_recall: 0.0134 - val_f1: nan\n",
      "Epoch 49/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0646 - accuracy: 0.4260 - precision: 0.6877 - recall: 0.0413 - f1: nan - val_loss: 1.0714 - val_accuracy: 0.4800 - val_precision: 0.2381 - val_recall: 0.0134 - val_f1: nan\n",
      "Epoch 50/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0691 - accuracy: 0.4203 - precision: 0.6327 - recall: 0.0397 - f1: nan - val_loss: 1.0749 - val_accuracy: 0.4650 - val_precision: 0.3929 - val_recall: 0.0179 - val_f1: nan\n",
      "Epoch 51/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0561 - accuracy: 0.4384 - precision: 0.7468 - recall: 0.0591 - f1: nan - val_loss: 1.0721 - val_accuracy: 0.4750 - val_precision: 0.2738 - val_recall: 0.0179 - val_f1: nan\n",
      "Epoch 52/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0508 - accuracy: 0.4420 - precision: 0.6758 - recall: 0.0602 - f1: nan - val_loss: 1.0728 - val_accuracy: 0.4800 - val_precision: 0.3929 - val_recall: 0.0179 - val_f1: nan\n",
      "Epoch 53/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0508 - accuracy: 0.4386 - precision: 0.6542 - recall: 0.0592 - f1: nan - val_loss: 1.0695 - val_accuracy: 0.5000 - val_precision: 0.2738 - val_recall: 0.0179 - val_f1: nan\n",
      "Epoch 54/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0606 - accuracy: 0.4335 - precision: 0.6644 - recall: 0.0610 - f1: nan - val_loss: 1.0693 - val_accuracy: 0.5000 - val_precision: 0.2738 - val_recall: 0.0179 - val_f1: nan\n",
      "Epoch 55/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0444 - accuracy: 0.4577 - precision: 0.7513 - recall: 0.0655 - f1: nan - val_loss: 1.0733 - val_accuracy: 0.4600 - val_precision: 0.4167 - val_recall: 0.0223 - val_f1: nan\n",
      "Epoch 56/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0543 - accuracy: 0.4323 - precision: 0.6557 - recall: 0.0618 - f1: nan - val_loss: 1.0737 - val_accuracy: 0.4550 - val_precision: 0.4167 - val_recall: 0.0223 - val_f1: nan\n",
      "Epoch 57/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0511 - accuracy: 0.4366 - precision: 0.6820 - recall: 0.0767 - f1: nan - val_loss: 1.0769 - val_accuracy: 0.4200 - val_precision: 0.3857 - val_recall: 0.0223 - val_f1: nan\n",
      "Epoch 58/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0489 - accuracy: 0.4480 - precision: 0.5934 - recall: 0.0671 - f1: nan - val_loss: 1.0686 - val_accuracy: 0.4850 - val_precision: 0.2857 - val_recall: 0.0179 - val_f1: nan\n",
      "Epoch 59/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0510 - accuracy: 0.4398 - precision: 0.7134 - recall: 0.0714 - f1: nan - val_loss: 1.0747 - val_accuracy: 0.4300 - val_precision: 0.4381 - val_recall: 0.0312 - val_f1: nan\n",
      "Epoch 60/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0530 - accuracy: 0.4324 - precision: 0.6277 - recall: 0.0859 - f1: nan - val_loss: 1.0692 - val_accuracy: 0.4750 - val_precision: 0.2738 - val_recall: 0.0179 - val_f1: nan\n",
      "Epoch 61/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0437 - accuracy: 0.4590 - precision: 0.6446 - recall: 0.0733 - f1: nan - val_loss: 1.0696 - val_accuracy: 0.4900 - val_precision: 0.2857 - val_recall: 0.0223 - val_f1: nan\n",
      "Epoch 62/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0519 - accuracy: 0.4366 - precision: 0.5907 - recall: 0.0743 - f1: nan - val_loss: 1.0699 - val_accuracy: 0.4900 - val_precision: 0.2738 - val_recall: 0.0179 - val_f1: nan\n",
      "Epoch 63/64\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.0498 - accuracy: 0.4537 - precision: 0.6577 - recall: 0.0780 - f1: nan - val_loss: 1.0758 - val_accuracy: 0.4750 - val_precision: 0.3619 - val_recall: 0.0223 - val_f1: nan\n",
      "Epoch 64/64\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.0415 - accuracy: 0.4423 - precision: 0.6685 - recall: 0.0736 - f1: nan - val_loss: 1.0738 - val_accuracy: 0.4650 - val_precision: 0.4286 - val_recall: 0.0312 - val_f1: nan\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "!python train2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiMzHYePrqTD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOE/Y5gbLOiyDuhObh0OrPX",
   "mount_file_id": "1li2jGQ0fISBOGUmy_4Unjm5kP_mgZPyr",
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
