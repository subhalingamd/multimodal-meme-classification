{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"},"colab":{"name":"cnn_w2v_wiki.ipynb","provenance":[],"collapsed_sections":["jzxuLR418gRW","SnjIBFel8gRa","mXZwrRi98gRa","bPbStedA8gRb","cHmo_5oq8gRd","tAQS9rsN8gRf","wCAwd2S48gRg","-9BXRcWA8gRi"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CIHkPnsHJ5Yr"},"source":["# My"]},{"cell_type":"code","metadata":{"id":"vxEDrNdVJ-Lh","executionInfo":{"status":"ok","timestamp":1619346444300,"user_tz":-330,"elapsed":1028,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["import os \n","\n","import pandas as pd\n","import numpy as np\n","\n","\n","from sklearn.model_selection import train_test_split\n","\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk import pos_tag\n","from nltk.corpus import stopwords\n","# from nltk.stem import WordNetLemmatizer\n","# from nltk.corpus import wordnet as wn\n","from collections import defaultdict\n","import regex as re\n","\n"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbVle2EJKwsM","executionInfo":{"status":"ok","timestamp":1619345687100,"user_tz":-330,"elapsed":31575,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"032e7adb-6a4f-4a8e-ebb0-08de89de7c2b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"UNxk7pTgKTnt","executionInfo":{"status":"ok","timestamp":1619347227424,"user_tz":-330,"elapsed":1168,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"85b01e37-e10d-4790-e990-77ce568763cc"},"source":["root = \"/content/drive/MyDrive/MTL782-Memes Classifier/dataminingmtl782/\"\n","train_path = \"train_images/train_images\"\n","test_path = \"test_images\"\n","\n","train_dt = pd.read_csv(\"/content/drive/MyDrive/MTL782-Memes Classifier/dataminingmtl782/train.csv\")\n","test_dt = pd.read_csv(\"/content/drive/MyDrive/MTL782-Memes Classifier/dataminingmtl782/test.csv\")\n","train_dt.head()"],"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>image id</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>label_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>image_2455.jpg</td>\n","      <td>- It is not our fight - Are we not part of thi...</td>\n","      <td>troll</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>image_3701.jpg</td>\n","      <td>THAT'S THE DIFFERENCE BETWEEN YOU AND ME  YOU...</td>\n","      <td>none</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>image_4166.png</td>\n","      <td>- WHAT DO THE TITANIC AND THE SIXTH SENSE HAVE...</td>\n","      <td>none</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>448_image_batch_2.png</td>\n","      <td>\"COME ON MAN, YOU KNOW THE THING.\\r\\nJUST ASK ...</td>\n","      <td>troll</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>653_image_batch_2.png</td>\n","      <td>\"Those who believe without reason cannot be co...</td>\n","      <td>none</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID               image id  ...  label label_num\n","0   1         image_2455.jpg  ...  troll         2\n","1   2         image_3701.jpg  ...   none         0\n","2   3         image_4166.png  ...   none         0\n","3   4  448_image_batch_2.png  ...  troll         2\n","4   5  653_image_batch_2.png  ...   none         0\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"code","metadata":{"id":"jv2oRn_7KqV3","executionInfo":{"status":"ok","timestamp":1619347227425,"user_tz":-330,"elapsed":650,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["def get_files_labels(subpath,csv):\n","    \"\"\"Gets paths images within a folder, and their labels\"\"\"\n","    img_paths, img_labels, texts = [], [], []\n","    df = pd.read_csv(root+csv)\n","    i=0\n","    for index, row in df.iterrows():\n","        try:\n","          img, text, label = row[\"image id\"], row[\"text\"], int(row[\"label_num\"])\n","        except:\n","          img, text, label = row[\"image id\"], row[\"text\"], -1\n","        # print(img_,\": \",text_)\n","        \n","        ## Change this for img....>>>\n","        ###if not (i in [858, 1986, 1990] and csv==\"train.csv\"):\n","        if True:\n","          img_paths.append(root+subpath+'/'+img.strip())\n","          img_labels.append(label)\n","          ###texts.append(preprocess_txt(text))\n","          ###texts.append(text)\n","          texts.append(text)\n","        i+=1\n","        #print('\\r images: {} labels : {}'.format(len(img_paths), len(img_labels)) )\n","    return img_paths, img_labels, texts"],"execution_count":93,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6U-h7TJKs2h","executionInfo":{"status":"ok","timestamp":1619347228418,"user_tz":-330,"elapsed":1091,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["files_, y_, texts_ = get_files_labels(train_path,\"train.csv\")\n","files_test, y_test, texts_test = get_files_labels(test_path,\"test.csv\")\n"],"execution_count":94,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9UgPZ1PWLvDN","executionInfo":{"status":"ok","timestamp":1619277648208,"user_tz":-330,"elapsed":632,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"27e24498-7db9-4323-fe7a-faf33a4d65d4"},"source":["len(texts_)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1991"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"VeYF1YR-8gRH"},"source":["# Emotion Classification in texts using LSTM and Word2Vec\n","\n","### Architecture: \n","(X) Text -> Embedding (W2V pretrained on wikipedia articles) -> Deep Network (CNN 1D) -> Fully connected (Dense) -> Output Layer (Softmax) -> Emotion class (Y)\n","\n","#### Embedding Layer\n","* Word Embedding is a representation of text where words that have the similar meaning have a similar representation. We will use 300 dimentional word vectors pre-trained on wikipedia articles. We can also train the w2v model with our data, however our dataset is quite small and trained word vectors might not be as good as using pretrained w2v.\n","\n","#### Deep Network\n","* Though text data is one-dimensional, we can use 1D convolutional neural networks to extract features from our data. The result of each convolution will fire when a special pattern is detected. By varying the size of the kernels and concatenating their outputs, you‚Äôre allowing yourself to detect patterns of multiples sizes (2, 3, or 5 adjacent words). Patterns could be expressions like ‚ÄúI hate‚Äù, ‚Äúvery good‚Äù and therefore CNNs can identify them in the sentence regardless of their position. \n","\n","#### Fully Connected Layer\n","* The fully connected layer takes the deep representation from the RNN/LSTM/GRU and transforms it into the final output classes or class scores. This component is comprised of fully connected layers along with batch normalization and optionally dropout layers for regularization.\n","\n","#### Output Layer\n","* Based on the problem at hand, this layer can have either Sigmoid for binary classification or Softmax for both binary and multi classification output."]},{"cell_type":"code","metadata":{"id":"Q9A4aHwNJ4Ka"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HUtHcbem8gRK"},"source":["## Workflow: \n","1. Import Data\n","2. Prepare the input data\n","3. Import pre-trained W2V\n","4. Create Neural Network Pipeline\n","5. Train The Model\n","6. Evaluate results\n","\n","\n","\n","üëã  **Let's start** "]},{"cell_type":"markdown","metadata":{"id":"sMgFKoif8gRL"},"source":["## 1. Import Data\n"]},{"cell_type":"code","metadata":{"id":"UHgS-xZe8gRM","executionInfo":{"status":"ok","timestamp":1619346460832,"user_tz":-330,"elapsed":589,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["import pandas as pd\n","import numpy as np\n","\n","# text preprocessing\n","from nltk.tokenize import word_tokenize\n","import re\n","\n","# plots and metrics\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n","\n","# preparing input to our model\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","\n","# keras layers\n","from keras.models import Sequential\n","from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jhq3n98N8gRN"},"source":["Defining vector space dimension and fixed input size"]},{"cell_type":"code","metadata":{"id":"-rF2olS78gRN","executionInfo":{"status":"ok","timestamp":1619346464659,"user_tz":-330,"elapsed":1149,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["# Number of labels: joy, anger, fear, sadness, neutral\n","num_classes = 5\n","\n","# Number of dimensions for word embedding\n","embed_num_dims = 300\n","\n","# Max input length (max number of words) \n","max_seq_len = 500\n","\n","class_names = ['joy', 'fear', 'anger', 'sadness', 'neutral']"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ufAN-9Bq8gRO"},"source":["Importing our training and testing datasets"]},{"cell_type":"code","metadata":{"id":"Vpk_0QqG8gRP","executionInfo":{"status":"ok","timestamp":1619346465885,"user_tz":-330,"elapsed":1087,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["data_train = pd.read_csv('data/data_train.csv', encoding='utf-8')\n","data_test = pd.read_csv('data/data_test.csv', encoding='utf-8')\n","\n","X_train = data_train.Text\n","X_test = data_test.Text\n","\n","y_train = data_train.Emotion\n","y_test = data_test.Emotion\n","\n","data = data_train.append(data_test, ignore_index=True)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"j009mZvv8gRP","executionInfo":{"status":"ok","timestamp":1619346467817,"user_tz":-330,"elapsed":1396,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"cefac857-a2e3-4ddc-ab1d-b6514d1ef5cc"},"source":["print(data.Emotion.value_counts())\n","data.head(6)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["joy        2326\n","sadness    2317\n","anger      2259\n","neutral    2254\n","fear       2171\n","Name: Emotion, dtype: int64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotion</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>neutral</td>\n","      <td>There are tons of other paintings that I thin...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sadness</td>\n","      <td>Yet the dog had grown old and less capable , a...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>fear</td>\n","      <td>When I get into the tube or the train without ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>fear</td>\n","      <td>This last may be a source of considerable disq...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>anger</td>\n","      <td>She disliked the intimacy he showed towards so...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>sadness</td>\n","      <td>When my family heard that my Mother's cousin w...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Emotion                                               Text\n","0  neutral   There are tons of other paintings that I thin...\n","1  sadness  Yet the dog had grown old and less capable , a...\n","2     fear  When I get into the tube or the train without ...\n","3     fear  This last may be a source of considerable disq...\n","4    anger  She disliked the intimacy he showed towards so...\n","5  sadness  When my family heard that my Mother's cousin w..."]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"j73p06BG8gRQ"},"source":["## 2. Prepare input data\n","To input the data to our NN Model we'll need some preprocessing:\n","1. Tokenize our texts and count unique tokens\n","2. Padding: each input (sentence or text) has to be of the same lenght\n","3. Labels have to be converted to integeres and categorized"]},{"cell_type":"markdown","metadata":{"id":"BmAkJq0Z8gRQ"},"source":["Basic preprocessing and tokenization using nltk to double check that sentences are properly split into words.\n","We could also add stopword removal but steps like stemming or lemmatization are not needed since we are using word2vec and words with the same stem can have a different meaning"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BZnO48pm8gRR","executionInfo":{"status":"ok","timestamp":1619346470376,"user_tz":-330,"elapsed":1409,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"5ef77747-1dbf-4650-e176-edb161596c47"},"source":["import nltk\n","nltk.download('punkt')\n","def clean_text(data):\n","    \n","    # remove hashtags and @usernames\n","    data = re.sub(r\"(#[\\d\\w\\.]+)\", '', data)\n","    data = re.sub(r\"(@[\\d\\w\\.]+)\", '', data)\n","    \n","    # tekenization using nltk\n","    data = word_tokenize(data)\n","    \n","    return data"],"execution_count":39,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M0LIfBS28gRR"},"source":["*Making things easier for keras tokenizer üôÉ"]},{"cell_type":"code","metadata":{"id":"EEcbh5hk8gRR","executionInfo":{"status":"ok","timestamp":1619346474758,"user_tz":-330,"elapsed":4463,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["texts = [' '.join(clean_text(text)) for text in data.Text]\n","\n","texts_train = [' '.join(clean_text(text)) for text in X_train]\n","texts_test = [' '.join(clean_text(text)) for text in X_test]"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6gpRqNyT8gRS","executionInfo":{"status":"ok","timestamp":1619346474761,"user_tz":-330,"elapsed":2188,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"65d1e8f9-caab-415b-e7b4-49661542726f"},"source":["print(texts_train[92])"],"execution_count":41,"outputs":[{"output_type":"stream","text":["a bit ? I 'm extremely annoyed that he did n't phone me when he promised me that he would ! He 's such a liar .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KrtKTRbF8gRS"},"source":["**Tokenization + fitting using keras**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ZgIc7FR8gRT","executionInfo":{"status":"ok","timestamp":1619346480290,"user_tz":-330,"elapsed":1682,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"7e59415b-2f1a-4581-888a-2cf0e88484a7"},"source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","\n","sequence_train = tokenizer.texts_to_sequences(texts_train)\n","sequence_test = tokenizer.texts_to_sequences(texts_test)\n","\n","index_of_words = tokenizer.word_index\n","\n","# vacab size is number of unique words + reserved 0 index for padding\n","vocab_size = len(index_of_words) + 1\n","\n","print('Number of unique words: {}'.format(len(index_of_words)))"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Number of unique words: 12088\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2hefPRpP8gRU"},"source":["**Padding** -> each input has the same length\n","\n","We defined maximun number of words for our texts and input size to our model has to be fixed - padding with zeros to keep the same input lenght (longest input in our dataset is ~250 words)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ehhnbZI18gRU","executionInfo":{"status":"ok","timestamp":1619346482131,"user_tz":-330,"elapsed":623,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"a2e912ad-a9c0-4160-e07c-d10d7a5dd7f3"},"source":["X_train_pad = pad_sequences(sequence_train, maxlen = max_seq_len )\n","X_test_pad = pad_sequences(sequence_test, maxlen = max_seq_len )\n","\n","X_train_pad"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[    0,     0,     0, ...,   119,    51,   345],\n","       [    0,     0,     0, ...,    37,   277,   154],\n","       [    0,     0,     0, ...,    16,     2,  1210],\n","       ...,\n","       [    0,     0,     0, ...,   876,     4,   909],\n","       [    0,     0,     0, ...,     1,     6,   117],\n","       [    0,     0,     0, ..., 10259,   173,    13]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"bXKMYYej8gRV"},"source":["**Categorize** labels: "]},{"cell_type":"code","metadata":{"id":"SgEeufo78gRV","executionInfo":{"status":"ok","timestamp":1619346486489,"user_tz":-330,"elapsed":999,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["encoding = {\n","    'joy': 0,\n","    'fear': 1,\n","    'anger': 2,\n","    'sadness': 3,\n","    'neutral': 4\n","}\n","\n","# Integer labels\n","y_train = [encoding[x] for x in data_train.Emotion]\n","y_test = [encoding[x] for x in data_test.Emotion]"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eo-QdKPd8gRV","executionInfo":{"status":"ok","timestamp":1619346488231,"user_tz":-330,"elapsed":630,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"b0e9677d-3974-4262-eca7-1f147620092b"},"source":["y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","y_train"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 1.],\n","       [0., 0., 0., 1., 0.],\n","       [0., 1., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., 1., 0.],\n","       [0., 1., 0., 0., 0.],\n","       [0., 0., 1., 0., 0.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"jzxuLR418gRW"},"source":["## 2. Import pretrained word vectors"]},{"cell_type":"markdown","metadata":{"id":"Hyfyi1hL8gRX"},"source":["* Importing pretrained word2vec from file and creating embedding matrix\n","* We will later map each word in our corpus to existing word vector"]},{"cell_type":"code","metadata":{"id":"77UKYzg-8gRX"},"source":["def create_embedding_matrix(filepath, word_index, embedding_dim):\n","    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n","    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n","    with open(filepath) as f:\n","        for line in f:\n","            word, *vector = line.split()\n","            if word in word_index:\n","                idx = word_index[word] \n","                embedding_matrix[idx] = np.array(\n","                    vector, dtype=np.float32)[:embedding_dim]\n","    return embedding_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CDe4wnDg8gRY"},"source":["You can download and import any pre-trained word embeddings. I will use 300 dimentional w2v pre-trained on wikipedia articles. Download fast text english vectors: https://fasttext.cc/docs/en/english-vectors.html"]},{"cell_type":"code","metadata":{"id":"S4k3P4JN8gRY"},"source":["import urllib.request\n","import zipfile\n","import os\n","\n","fname = 'embeddings/wiki-news-300d-1M.vec'\n","\n","if not os.path.isfile(fname):\n","    print('Downloading word vectors...')\n","    urllib.request.urlretrieve('https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip',\n","                              'wiki-news-300d-1M.vec.zip')\n","    print('Unzipping...')\n","    with zipfile.ZipFile('wiki-news-300d-1M.vec.zip', 'r') as zip_ref:\n","        zip_ref.extractall('embeddings')\n","    print('done.')\n","    \n","    os.remove('wiki-news-300d-1M.vec.zip')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"38oyM1Sl8gRY"},"source":["embedd_matrix = create_embedding_matrix(fname, index_of_words, embed_num_dims)\n","embedd_matrix.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J1vj3Si98gRZ"},"source":["Some of the words from our corpus were not included in the pre-trained word vectors. If we inspect those words we'll see that it's mostly spelling errors. It's also good to double check the noise in our data f.e different languages or tokenizer errors."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"qCge4zlH8gRa"},"source":["# Inspect unseen words\n","new_words = 0\n","\n","for word in index_of_words:\n","    entry = embedd_matrix[index_of_words[word]]\n","    if all(v == 0 for v in entry):\n","        new_words = new_words + 1\n","\n","print('Words found in wiki vocab: ' + str(len(index_of_words) - new_words))\n","print('New words found: ' + str(new_words))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SnjIBFel8gRa"},"source":["## 3. Create CNN Pipeline"]},{"cell_type":"markdown","metadata":{"id":"mXZwrRi98gRa"},"source":["### Embedding Layer\n","\n","We will use pre-trained word vectors. We could also train our own embedding layer if we don't specify the pre-trained weights \n","\n","* **vocabulary size:** the maximum number of terms that are used to represent a text: e.g. if we set the size of the ‚Äúvocabulary‚Äù to 1000 only the first thousand terms most frequent in the corpus will be considered (and the other terms will be ignored)\n","* **the maximum length:** of the texts (which must all be the same length)\n","* **size of embeddings:** basically, the more dimensions we have the more precise the semantics will be, but beyond a certain threshold we will lose the ability of the embedding to define a coherent and general enough semantic area\n","* **trainable:** True if you want to fine-tune them while training\n"]},{"cell_type":"code","metadata":{"id":"w272MLVG8gRb"},"source":["# Embedding layer before the actaul BLSTM \n","embedd_layer = Embedding(vocab_size,\n","                         embed_num_dims,\n","                         input_length = max_seq_len,\n","                         weights = [embedd_matrix],\n","                         trainable=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bPbStedA8gRb"},"source":["### Model Pipeline\n","- the input is the first N words of each text (with proper padding)\n","- the first level creates embedding of words, using vocabulary with a certain dimension, and a given size of embeddings\n","- we will use 1D convolutional neural network to extract features from our data. The result of each convolution will fire when a special pattern is detected. By varying the size of the kernels and concatenating their outputs, you‚Äôre allowing yourself to detect patterns of multiples sizes (2, 3, or 5 adjacent words)\n","- the output level has a number of neurons equal to the classes of the problem and a ‚Äúsoftmax‚Äù activation function"]},{"cell_type":"code","metadata":{"id":"cnEWF4pt8gRc"},"source":["# Convolution\n","kernel_size = 3\n","filters = 256\n","\n","model = Sequential()\n","model.add(embedd_layer)\n","model.add(Conv1D(filters, kernel_size, activation='relu'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1HuToMnq8gRd"},"source":["model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cHmo_5oq8gRd"},"source":["## 3. Train the Model"]},{"cell_type":"code","metadata":{"id":"fv5Sd3TE8gRe"},"source":["batch_size = 256\n","epochs = 6\n","\n","hist = model.fit(X_train_pad, y_train, \n","                 batch_size=batch_size,\n","                 epochs=epochs,\n","                 validation_data=(X_test_pad,y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mka0yOVs8gRe"},"source":["# Accuracy plot\n","plt.plot(hist.history['acc'])\n","plt.plot(hist.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()\n","\n","# Loss plot\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tAQS9rsN8gRf"},"source":["## 4. Evaluation"]},{"cell_type":"code","metadata":{"id":"dTIm-0ba8gRf"},"source":["predictions = model.predict(X_test_pad)\n","predictions = np.argmax(predictions, axis=1)\n","predictions = [class_names[pred] for pred in predictions]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6NXjCNvL8gRg"},"source":["print(\"Accuracy: {:.2f}%\".format(accuracy_score(data_test.Emotion, predictions) * 100))\n","print(\"\\nF1 Score: {:.2f}\".format(f1_score(data_test.Emotion, predictions, average='micro') * 100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wCAwd2S48gRg"},"source":["#### Plotting confusion Matrix:"]},{"cell_type":"code","metadata":{"id":"txqhw4F08gRh"},"source":["def plot_confusion_matrix(y_true, y_pred, classes,\n","                          normalize=False,\n","                          title=None,\n","                          cmap=plt.cm.Blues):\n","    '''\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    '''\n","    if not title:\n","        if normalize:\n","            title = 'Normalized confusion matrix'\n","        else:\n","            title = 'Confusion matrix, without normalization'\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    fig, ax = plt.subplots()\n","    \n","    # Set size\n","    fig.set_size_inches(12.5, 7.5)\n","    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","    ax.figure.colorbar(im, ax=ax)\n","    ax.grid(False)\n","    \n","    # We want to show all ticks...\n","    ax.set(xticks=np.arange(cm.shape[1]),\n","           yticks=np.arange(cm.shape[0]),\n","           # ... and label them with the respective list entries\n","           xticklabels=classes, yticklabels=classes,\n","           title=title,\n","           ylabel='True label',\n","           xlabel='Predicted label')\n","\n","    # Rotate the tick labels and set their alignment.\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","             rotation_mode=\"anchor\")\n","\n","    # Loop over data dimensions and create text annotations.\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, format(cm[i, j], fmt),\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    fig.tight_layout()\n","    return ax"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOYLnxlA8gRh"},"source":["print(\"\\nF1 Score: {:.2f}\".format(f1_score(data_test.Emotion, predictions, average='micro') * 100))\n","\n","# Plot normalized confusion matrix\n","plot_confusion_matrix(data_test.Emotion, predictions, classes=class_names, normalize=True, title='Normalized confusion matrix')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-9BXRcWA8gRi"},"source":["#### Let's try other inputs:"]},{"cell_type":"code","metadata":{"id":"8nTc0gz58gRi"},"source":["print('Message: {}\\nPredicted: {}'.format(X_test[4], predictions[4]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQrynIqw8gRj"},"source":["import time\n","\n","message = ['delivery was hour late and my pizza was cold!']\n","\n","seq = tokenizer.texts_to_sequences(message)\n","padded = pad_sequences(seq, maxlen=max_seq_len)\n","\n","start_time = time.time()\n","pred = model.predict(padded)\n","\n","print('Message: ' + str(message))\n","print('predicted: {} ({:.2f} seconds)'.format(class_names[np.argmax(pred)], (time.time() - start_time)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Un9GOV7u8gRj"},"source":["# Done\n","Save the model for later use üôÉ "]},{"cell_type":"code","metadata":{"id":"eMvc8SOU8gRk"},"source":["# creates a HDF5 file 'my_model.h5'\n","model.save('models/cnn_w2v.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H7yuTJxWZvD0","executionInfo":{"status":"ok","timestamp":1619346508159,"user_tz":-330,"elapsed":732,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["#$# !pip install ktrain"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"Io9msJG_8gRk","executionInfo":{"status":"ok","timestamp":1619346585009,"user_tz":-330,"elapsed":787,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["from keras.models import load_model\n","predictor = load_model('models/cnn_w2v.h5')\n","\n","##import ktrain\n","##predictor = ktrain.load_predictor(\"models/bert_models\")"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"HCvvdJ1jPnvg","executionInfo":{"status":"ok","timestamp":1619346588244,"user_tz":-330,"elapsed":811,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["files_, y_, texts_ = get_files_labels(train_path,\"train.csv\")\n","files_test, y_test, _texts_test = get_files_labels(test_path,\"test.csv\")"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQipGPCZ98Mm","executionInfo":{"status":"ok","timestamp":1619346621114,"user_tz":-330,"elapsed":909,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"4f3296ff-d4a6-44c0-8313-7925961c5018"},"source":["import time\n","\n","message = ['''so sad that Steve Jobs died of Ligma who's steve Jobs? Ligma Balls''']\n","\n","seq = tokenizer.texts_to_sequences(message)\n","padded = pad_sequences(seq, maxlen=max_seq_len)\n","##padded = message\n","\n","start_time = time.time()\n","pred = predictor.predict(padded)\n","\n","print('Message: ' + str(message))\n","print('predicted: {} ({:.2f} seconds)'.format(pred, (time.time() - start_time)))"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Message: [\"so sad that Steve Jobs died of Ligma who's steve Jobs? Ligma Balls\"]\n","predicted: [[8.1978964e-05 3.1834701e-05 1.3791790e-04 9.9969125e-01 5.7124969e-05]] (0.04 seconds)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WXCKTOgf-h0U","executionInfo":{"status":"ok","timestamp":1619346624471,"user_tz":-330,"elapsed":1265,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"bd1d9fe6-997f-4c40-ccaa-27d2a97621c9"},"source":["import time\n","\n","seq = tokenizer.texts_to_sequences(texts_[0:50])\n","padded = pad_sequences(seq, maxlen=max_seq_len)\n","\n","start_time = time.time()\n","pred_train = predictor.predict(padded)\n","\n","pred_ = np.argmax(pred_train,axis=1)\n","\n","print('Message: ' + str(message))\n","print('predicted: {} ({:.2f} seconds)'.format(pred_, (time.time() - start_time)))\n","print('gold: {} '.format(y_[:50]))"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Message: [\"so sad that Steve Jobs died of Ligma who's steve Jobs? Ligma Balls\"]\n","predicted: [4 1 1 1 1 0 4 0 1 0 1 4 3 1 1 4 0 4 2 2 4 2 3 1 1 2 4 1 1 4 1 2 1 3 0 2 2\n"," 4 1 1 2 4 2 2 1 4 1 1 4 0] (0.56 seconds)\n","gold: [2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 2, 1, 0, 1, 1, 0, 0, 0, 0, 2, 0, 1, 0, 2, 0, 1, 1, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 1, 1, 1, 1] \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"me_6fdK8ME_P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619346631129,"user_tz":-330,"elapsed":779,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"96aae236-54a7-44be-a12d-7e8117d90ebc"},"source":["#print(*sorted(zip(pred_,y_[:50])),sep=\"\\n\")\n","print(pred[0])"],"execution_count":53,"outputs":[{"output_type":"stream","text":["[8.1978964e-05 3.1834701e-05 1.3791790e-04 9.9969125e-01 5.7124969e-05]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vC7QckLLNEdI","executionInfo":{"status":"ok","timestamp":1619346634246,"user_tz":-330,"elapsed":738,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["_text_train, _text_val, _y_train, _y_val = train_test_split(\n","    texts_, y_, test_size=0.1, random_state=42, stratify=y_, shuffle=True)\n","#X_test = np.column_stack([files_test,texts_test])\n","# X_train[0]"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qITz48h4OAdY","executionInfo":{"status":"ok","timestamp":1619346639777,"user_tz":-330,"elapsed":687,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"b7ae01bf-adfd-4d8f-961f-5b2b755655f4"},"source":["len(_text_train), len(_text_val), len(_y_train), len(_y_val)"],"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1791, 200, 1791, 200)"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"nP_cZSATOJe5","executionInfo":{"status":"ok","timestamp":1619346705455,"user_tz":-330,"elapsed":1230,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["import time\n","\n","seq = tokenizer.texts_to_sequences(_text_train)\n","padded = pad_sequences(seq, maxlen=max_seq_len)\n","\n","#padded  = _text_train\n","\n","start_time = time.time()\n","pred_train = predictor.predict(padded)\n","\n","pred_ = np.argmax(pred_train,axis=1)\n","\n","#print('Message: ' + str(message))\n","#print('predicted: {} ({:.2f} seconds)'.format(pred_, (time.time() - start_time)))\n","#print('gold: {} '.format(y_[:50]))"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"gEHoupayRmDq","executionInfo":{"status":"ok","timestamp":1619346727712,"user_tz":-330,"elapsed":970,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["import time\n","\n","seq = tokenizer.texts_to_sequences(_text_val)\n","padded = pad_sequences(seq, maxlen=max_seq_len)\n","\n","start_time = time.time()\n","pred_val = predictor.predict(padded)\n","\n","pred_ = np.argmax(pred_val,axis=1)\n","\n","#print('Message: ' + str(message))\n","#print('predicted: {} ({:.2f} seconds)'.format(pred_, (time.time() - start_time)))\n","#print('gold: {} '.format(y_[:50]))"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0roRVwedXZd","executionInfo":{"status":"ok","timestamp":1619347173560,"user_tz":-330,"elapsed":779,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["import pickle\n","pickle.dump(pred_train, open(\"__cnn_pred_train.pkl\", 'wb'))\n","pickle.dump(pred_val, open(\"__cnn_pred_val.pkl\", 'wb'))\n"],"execution_count":90,"outputs":[]},{"cell_type":"code","metadata":{"id":"QUGrvP4Xchro"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XlOyLkh0Tqz0","executionInfo":{"status":"ok","timestamp":1619346870364,"user_tz":-330,"elapsed":1096,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"20bb1d85-ea42-486c-b9be-21850d488903"},"source":["from sklearn.svm import SVC,LinearSVC\n","from sklearn.tree import DecisionTreeClassifier\n","svc = DecisionTreeClassifier()\n","svc.fit(pred_train,_y_train)"],"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier()"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89Qnj_49UE8T","executionInfo":{"status":"ok","timestamp":1619346870365,"user_tz":-330,"elapsed":1069,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"2aedf7e3-a154-4948-a444-00c9aaa956cb"},"source":["from sklearn.metrics import classification_report\n","print(classification_report(svc.predict(pred_train), _y_train))"],"execution_count":83,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00       547\n","           1       1.00      1.00      1.00       623\n","           2       0.99      1.00      0.99       621\n","\n","    accuracy                           1.00      1791\n","   macro avg       1.00      1.00      1.00      1791\n","weighted avg       1.00      1.00      1.00      1791\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1U42xK_3Sdks","executionInfo":{"status":"ok","timestamp":1619347114439,"user_tz":-330,"elapsed":750,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"1df48cea-7fed-424d-c113-487984cee336"},"source":["from sklearn.metrics import classification_report\n","print(classification_report(svc.predict(pred_val[100:150]), _y_val[100:150]))"],"execution_count":89,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.38      0.33      0.35        18\n","           1       0.33      0.35      0.34        17\n","           2       0.44      0.47      0.45        15\n","\n","    accuracy                           0.38        50\n","   macro avg       0.38      0.38      0.38        50\n","weighted avg       0.38      0.38      0.38        50\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5QoTG7ZrTrN0","executionInfo":{"status":"ok","timestamp":1619346883804,"user_tz":-330,"elapsed":1019,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["import pickle\n","pickle.dump(svc, open(\"nlptone__dt6_b.sav\", 'wb'))"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"id":"CDQ3H64HlwYM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2RDbQPFWlxHT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yJ9WhUqUOhln","executionInfo":{"status":"ok","timestamp":1619343511417,"user_tz":-330,"elapsed":7842,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"611cb9f6-a020-4cce-cceb-463dbc6e9c7b"},"source":["len(pred_)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1791"]},"metadata":{"tags":[]},"execution_count":176}]},{"cell_type":"code","metadata":{"id":"Rrd19iSCOl7-"},"source":["import collections\n","occurrences = collections.Counter(sorted(zip(pred_,_y_train)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvCbCTT6QhKF"},"source":["l = collections.Counter(_y_train)\n","#l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oL5nqindO52q"},"source":["#occurrences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iU8x5PC8Q06f"},"source":["#for key,val in occurrences.items():\n","#  print(key,val/l[key[1]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nTYmr7ANO8Nw"},"source":["#m = {0:0,1:2,2:1,3:2,4:0}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jcwxns98R8Ig","executionInfo":{"status":"ok","timestamp":1619343513567,"user_tz":-330,"elapsed":864,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"01d617ce-941e-4a99-a698-8251b682d473"},"source":["len(pred_)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["200"]},"metadata":{"tags":[]},"execution_count":183}]},{"cell_type":"code","metadata":{"id":"rIM0HuQdR-V_"},"source":["#pred_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dz0nop9mSBI6"},"source":["#for i in range(200):\n","#  pred_[i] = m[pred_[i]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5wZrtXNfSJdN"},"source":["#pred_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HjkURQr2Sq3B"},"source":["svc.predict_proba(pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WhOj63-V1aG"},"source":["import pickle\n","pickle.dump(svc, open(\"nlptone__dt2.sav\", 'wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DW_TUdIOXIb0"},"source":["\"\"\"\n","import pickle\n","svc = pickle.load(open(\"nlptone__dt.sav\", 'rb'))\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rsOwu3pSfFAz","executionInfo":{"status":"ok","timestamp":1619347275508,"user_tz":-330,"elapsed":930,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["import time\n","\n","seq = tokenizer.texts_to_sequences(_texts_test)\n","padded = pad_sequences(seq, maxlen=max_seq_len)\n","\n","start_time = time.time()\n","pred_test = predictor.predict(padded)\n","\n","#pred_ = np.argmax(_texts_test,axis=1)\n","\n","#print('Message: ' + str(message))\n","#print('predicted: {} ({:.2f} seconds)'.format(pred_, (time.time() - start_time)))\n","#print('gold: {} '.format(y_[:50]))\n","\n"],"execution_count":95,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kFNiDgEVnpxS","executionInfo":{"status":"ok","timestamp":1619347290582,"user_tz":-330,"elapsed":852,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"41c4edbb-f4bf-4a51-ceca-debbe7356b01"},"source":["pred_test.shape"],"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(600, 5)"]},"metadata":{"tags":[]},"execution_count":96}]},{"cell_type":"code","metadata":{"id":"GX44U5RYntRd","executionInfo":{"status":"ok","timestamp":1619347339320,"user_tz":-330,"elapsed":770,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["import pickle\n","pickle.dump(pred_test, open(\"__cnn_pred_test.pkl\", 'wb'))\n"],"execution_count":97,"outputs":[]},{"cell_type":"code","metadata":{"id":"FPI61-OVoUzU","executionInfo":{"status":"ok","timestamp":1619347537274,"user_tz":-330,"elapsed":573,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["import pickle\n","pickle.dump(_y_train, open(\"__cnn_y_train.pkl\", 'wb'))\n","pickle.dump(_y_val, open(\"__cnn_y_val.pkl\", 'wb'))\n"],"execution_count":98,"outputs":[]},{"cell_type":"code","metadata":{"id":"KeL1ouTzfqMt"},"source":["print(*svc.predict(pred), sep=\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwHo_wgBgM97","executionInfo":{"status":"ok","timestamp":1619278736787,"user_tz":-330,"elapsed":950,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}},"outputId":"b9417948-92e9-4d54-b7ca-d0544bd85158"},"source":["len(texts_test)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["600"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"CVjfsMJ0h_kR","executionInfo":{"status":"ok","timestamp":1619345794015,"user_tz":-330,"elapsed":56528,"user":{"displayName":"Subhalingam D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86bQ1NVmL-U0-lCsAdMpCA_G3d9fxrw_PlOwtJg=s64","userId":"08059846138458314824"}}},"source":["!cp -r \"/content/drive/MyDrive/MTL782-Memes Classifier/bert_model\" models/bert_models/"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"88XCu_TxZbhE"},"source":[""],"execution_count":null,"outputs":[]}]}